// ğŸ¯ NutriRoom AIè¿”ç­”ãƒ™ãƒ¼ã‚¹éŸ³å£°åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ  - ã‚ˆã‚Šæ­£ç¢ºã§ä¸€è²«ã—ãŸéŸ³å£°é¸æŠ

export type AIResponseType = 
  | 'encouragement'          // åŠ±ã¾ã—ãƒ»ã‚µãƒãƒ¼ãƒˆ
  | 'agreement'              // å…±æ„Ÿãƒ»ã‚ã„ã¥ã¡
  | 'emotional_support'      // æ„Ÿæƒ…ã‚µãƒãƒ¼ãƒˆ
  | 'nutrition_advice'       // æ „é¤Šã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆå°‚é–€çš„ï¼‰
  | 'food_discussion'        // é£Ÿã¹ç‰©é›‘è«‡
  | 'general_conversation'   // ä¸€èˆ¬ä¼šè©±
  | 'initial_greeting'       // åˆæœŸæŒ¨æ‹¶
  | 'thinking'               // è€ƒãˆã¦ã„ã‚‹è¡¨ç¾

export interface AIResponseAnalysis {
  responseType: AIResponseType
  shouldPlayVoice: boolean
  voiceFile?: string
  confidence: number
  reasoning: string
  detectedPatterns: string[]
}

// ã€æ ¸å¿ƒæ©Ÿèƒ½ã€‘AIè¿”ç­”è§£æã«ã‚ˆã‚‹éŸ³å£°åˆ¤å®š - ç²¾åº¦å‘ä¸Šç‰ˆ
export function analyzeAiResponseForVoice(aiResponse: string): AIResponseAnalysis {
  console.log(`ğŸ¯ Analyzing AI response for voice: "${aiResponse.substring(0, 50)}..."`)
  
  const response = aiResponse.toLowerCase()
  const detectedPatterns: string[] = []
  
  // ã€å„ªå…ˆåº¦1ã€‘æœ¬ç‰©ã®åŠ±ã¾ã—ãƒ»æ„Ÿæƒ…ã‚µãƒãƒ¼ãƒˆï¼ˆå³æ ¼åˆ¤å®šï¼‰
  const genuineEncouragementPatterns = [
    'ç´ æ™´ã‚‰ã—ã„æ±ºæ„', 'å…¨åŠ›ã§ã‚µãƒãƒ¼ãƒˆ', 'ä¸€ç·’ã«é ‘å¼µã‚Š', 'å¿œæ´ã—ã¾ã™',
    'å¤§ä¸ˆå¤«ã§ã™', 'å®‰å¿ƒã—ã¦ãã ã•ã„', 'ãã£ã¨ã§ãã¾ã™', 'è² ã‘ãªã„ã§',
    'ãƒ•ã‚¡ã‚¤ãƒˆ', 'ã‚ãªãŸãªã‚‰', 'ç§ãŒæ”¯ãˆã¾ã™', 'åŠ±ã¾ã—', 'é ‘å¼µã£ã¦',
    'å¿œæ´ã—', 'æ”¯æ´ã—', 'ã‚µãƒãƒ¼ãƒˆã—', 'å¯„ã‚Šæ·»ã„', 'ä¸€ç·’ã«ä¹—ã‚Šè¶Šãˆ'
  ]
  
  const foundGenuineEncouragement = genuineEncouragementPatterns.filter(pattern => response.includes(pattern))
  if (foundGenuineEncouragement.length > 0) {
    detectedPatterns.push(...foundGenuineEncouragement)
    console.log('âœ… AI response type: genuine_encouragement (voice enabled)')
    return createAnalysis('encouragement', true, 'akari_encouragement.wav', 0.95, 
      'AI response contains genuine encouragement/emotional support', detectedPatterns)
  }
  
  // ã€å„ªå…ˆåº¦2ã€‘é£Ÿã¹ç‰©ã«ã¤ã„ã¦ã®é›‘è«‡ãƒ»å…±æ„Ÿï¼ˆéŸ³å£°ä¸è¦ï¼‰
  const foodDiscussionPatterns = [
    'ç¾å‘³ã—ã„', 'å¥½ã', 'é£Ÿã¹', 'æ–™ç†', 'å‘³', 'é¦™ã‚Š', 'ã§ã™ã‚ˆã­',
    'ãƒ¬ã‚·ãƒ”', 'ä½œã‚Šæ–¹', 'é£Ÿæ„Ÿ', 'æ—¬', 'å­£ç¯€', 'ãŠã™ã™ã‚',
    'ã„ã„ã§ã™ã­', 'ãã†ã§ã™ã­', 'çŸ¥ã£ã¦ã¾ã™', 'äººæ°—', 'å®šç•ª',
    'èª¿ç†', 'ææ–™', 'é£Ÿæ', 'é¢¨å‘³', 'é£Ÿã¹æ–¹', 'ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆ',
    'æ¸©ã‹ã„', 'å†·ãŸã„', 'ç”˜ã„', 'è¾›ã„', 'é…¸ã£ã±ã„', 'ãƒãƒƒã‚­ãƒ¼'
  ]
  
  const foundFood = foodDiscussionPatterns.filter(pattern => response.includes(pattern))
  if (foundFood.length > 0) {
    detectedPatterns.push(...foundFood)
    console.log('âŒ AI response type: food_discussion (text-only - casual food talk)')
    return createAnalysis('food_discussion', false, undefined, 0.9,
      'AI response is casual food discussion - text-only appropriate', detectedPatterns)
  }
  
  // ã€å„ªå…ˆåº¦3ã€‘é‡è¦ãªå…±æ„Ÿãƒ»ç†è§£ï¼ˆé£Ÿã¹ç‰©æ–‡è„ˆä»¥å¤–ã§ã®æ·±ã„ç†è§£ï¼‰
  const deepAgreementPatterns = [
    'ã‚ˆãç†è§£', 'æ°—æŒã¡', 'ã‚ˆãã‚ã‹ã‚Š', 'ãã†ãªã‚“ã§ã™',
    'ã‚ã‹ã‚‹', 'ç†è§£ã§ã', 'å…±æ„Ÿ', 'ãã®æ°—æŒã¡', 'ãŠã£ã—ã‚ƒã‚‹é€šã‚Š'
  ]
  
  const foundDeepAgreement = deepAgreementPatterns.filter(pattern => response.includes(pattern))
  if (foundDeepAgreement.length > 0) {
    detectedPatterns.push(...foundDeepAgreement)
    console.log('âœ… AI response type: deep_agreement (voice enabled)')
    return createAnalysis('agreement', true, 'akari_agreement.wav', 0.85,
      'AI response shows deep understanding/empathy', detectedPatterns)
  }
  
  // ã€å„ªå…ˆåº¦4ã€‘è»½ã„å…±æ„Ÿãƒ»ã‚ã„ã¥ã¡ï¼ˆé£Ÿã¹ç‰©æ–‡è„ˆãƒã‚§ãƒƒã‚¯ï¼‰
  const lightAgreementPatterns = [
    'ãã†ã§ã™ã­', 'ãªã‚‹ã»ã©', 'ã„ã„ã§ã™ã­', 'ã‚ã‹ã‚Šã¾ã™', 'åˆ†ã‹ã‚Šã¾ã™', 'åŒæ„Ÿ', 'ãã®é€šã‚Š'
  ]
  
  const foundLightAgreement = lightAgreementPatterns.filter(pattern => response.includes(pattern))
  if (foundLightAgreement.length > 0) {
    // é£Ÿã¹ç‰©æ–‡è„ˆã§ã®è»½ã„å…±æ„Ÿã¯ food_discussion ã¨ã—ã¦æ‰±ã†
    const isFoodContext = response.includes('ç¾å‘³ã—ã„') || 
                         response.includes('é£Ÿã¹') || 
                         response.includes('æ–™ç†') ||
                         response.includes('å‘³') ||
                         response.includes('å¥½ã')
    
    if (isFoodContext) {
      detectedPatterns.push(...foundLightAgreement, 'food_context')
      console.log('âŒ AI response type: food_discussion (light agreement in food context)')
      return createAnalysis('food_discussion', false, undefined, 0.8,
        'Light agreement in food context - text-only appropriate', detectedPatterns)
    } else {
      detectedPatterns.push(...foundLightAgreement)
      console.log('âœ… AI response type: light_agreement (voice enabled)')
      return createAnalysis('agreement', true, 'akari_agreement.wav', 0.75,
        'AI response shows light agreement/acknowledgment', detectedPatterns)
    }
  }
  
  // ã€å„ªå…ˆåº¦5ã€‘æ·±åˆ»ãªæ„Ÿæƒ…çš„ã‚µãƒãƒ¼ãƒˆï¼ˆé‡è¦ãªæ„Ÿæƒ…çŠ¶æ³ã§ã®æ”¯æ´ï¼‰
  const emotionalSupportPatterns = [
    'å…ƒæ°—å‡ºã—ã¦', 'æ¥½ã—ã„æ°—æŒã¡', 'å¬‰ã—ã„æ°—æŒã¡', 'å–œã³', 'å¹¸ã›',
    'è½ã¡è¾¼ã‚“ã§', 'æ‚²ã—ã„', 'è¾›ã„', 'å¤§å¤‰', 'å›°é›£',
    'ä¹—ã‚Šè¶Šãˆ', 'å…‹æœ', 'å‰å‘ã', 'ãƒã‚¸ãƒ†ã‚£ãƒ–',
    'å¯„ã‚Šæ·»', 'å´ã«ã„', 'ç†è§£ã—ã¾ã™', 'å¿ƒé…ã—ãªã„ã§'
  ]
  
  const foundEmotional = emotionalSupportPatterns.filter(pattern => response.includes(pattern))
  if (foundEmotional.length > 0) {
    detectedPatterns.push(...foundEmotional)
    console.log('âœ… AI response type: emotional_support (voice enabled)')
    return createAnalysis('emotional_support', true, 'akari_support.wav', 0.8,
      'AI response provides important emotional support', detectedPatterns)
  }
  
  // ã€å„ªå…ˆåº¦6ã€‘æ „é¤Šãƒ»å¥åº·ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç³»ï¼ˆå°‚é–€çš„ãªèª¬æ˜ - éŸ³å£°ãªã—ï¼‰
  const nutritionAdvicePatterns = [
    'ã‚¿ãƒ³ãƒ‘ã‚¯è³ª', 'ãƒ“ã‚¿ãƒŸãƒ³', 'ã‚«ãƒ­ãƒªãƒ¼', 'æ „é¤Šç´ ', 'ãƒŸãƒãƒ©ãƒ«',
    'é£Ÿç‰©ç¹Šç¶­', 'ç‚­æ°´åŒ–ç‰©', 'è„‚è³ª', 'ãƒãƒ©ãƒ³ã‚¹', 'æ‘‚å–',
    'åŠ¹æœ', 'æˆåˆ†', 'å«ã¾ã‚Œ', 'è±Šå¯Œ', 'æ¨å¥¨',
    '1æ—¥', 'ã‚°ãƒ©ãƒ ', 'ç›®å®‰', 'å¿…è¦é‡', 'ä¸è¶³',
    'éå‰°', 'é©é‡', 'ä»£è¬', 'æ¶ˆåŒ–', 'å¸å'
  ]
  
  const foundNutrition = nutritionAdvicePatterns.filter(pattern => response.includes(pattern))
  if (foundNutrition.length >= 2) { // è¤‡æ•°ã®å°‚é–€ç”¨èªãŒå«ã¾ã‚Œã‚‹å ´åˆ
    detectedPatterns.push(...foundNutrition)
    console.log('âŒ AI response type: nutrition_advice (text-only - professional info)')
    return createAnalysis('nutrition_advice', false, undefined, 0.85,
      'AI response contains detailed nutritional information', detectedPatterns)
  }
  
  // è€ƒãˆã¦ã„ã‚‹è¡¨ç¾ï¼ˆçŸ­ã„ã‚ã„ã¥ã¡çš„ãªéŸ³å£°ï¼‰
  const thinkingPatterns = [
    'ã†ãƒ¼ã‚“', 'ãã†ã§ã™ã­...', 'è€ƒãˆã¦', 'ã©ã†ã§ã—ã‚‡ã†',
    'ã¡ã‚‡ã£ã¨', 'å°‘ã—', 'ã¾ã‚', 'ã†ã‚“'
  ]
  
  const foundThinking = thinkingPatterns.filter(pattern => response.includes(pattern))
  if (foundThinking.length > 0 && aiResponse.length < 30) {
    detectedPatterns.push(...foundThinking)
    console.log('âœ… AI response type: thinking (voice enabled - short)')
    return createAnalysis('thinking', true, 'akari_thinking.wav', 0.7,
      'AI response is short thinking expression', detectedPatterns)
  }
  
  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šä¸€èˆ¬ä¼šè©±ï¼ˆéŸ³å£°ãªã—ï¼‰
  console.log('âŒ AI response type: general_conversation (text-only)')
  return createAnalysis('general_conversation', false, undefined, 0.6,
    'AI response is general conversation', detectedPatterns)
}

// åˆ†æçµæœä½œæˆãƒ˜ãƒ«ãƒ‘ãƒ¼
function createAnalysis(
  type: AIResponseType, 
  shouldPlay: boolean, 
  voiceFile: string | undefined,
  confidence: number,
  reasoning: string,
  patterns: string[]
): AIResponseAnalysis {
  return {
    responseType: type,
    shouldPlayVoice: shouldPlay,
    voiceFile,
    confidence,
    reasoning,
    detectedPatterns: patterns
  }
}

// ã€æ”¹å–„ç‰ˆã€‘éŸ³å£°å†ç”Ÿåˆ¤å®šï¼ˆAIè¿”ç­”ãƒ™ãƒ¼ã‚¹ï¼‰
export function shouldPlayVoiceForResponse(
  responseType: AIResponseType, 
  isInitialGreeting: boolean
): boolean {
  console.log(`=== Voice Decision (AI Response Based) ===`)
  console.log(`Response type: ${responseType}`)
  console.log(`Is initial greeting: ${isInitialGreeting}`)
  
  if (isInitialGreeting) {
    console.log('âœ… Voice enabled: Initial greeting')
    return true
  }
  
  switch (responseType) {
    case 'encouragement':        // åŠ±ã¾ã—ãƒ»ã‚µãƒãƒ¼ãƒˆ
    case 'agreement':           // å…±æ„Ÿãƒ»ã‚ã„ã¥ã¡
    case 'emotional_support':   // æ„Ÿæƒ…ã‚µãƒãƒ¼ãƒˆ
    case 'thinking':            // è€ƒãˆã¦ã„ã‚‹ï¼ˆçŸ­ã„ï¼‰
      console.log(`âœ… Voice enabled: ${responseType} (emotional connection)`)
      return true
      
    case 'nutrition_advice':    // æ „é¤Šã‚¢ãƒ‰ãƒã‚¤ã‚¹
    case 'food_discussion':     // é£Ÿã¹ç‰©é›‘è«‡
    case 'general_conversation': // ä¸€èˆ¬ä¼šè©±
      console.log(`âŒ Voice disabled: ${responseType} (text-only appropriate)`)
      return false
      
    default:
      console.log(`âŒ Voice disabled: Unknown type ${responseType}`)
      return false
  }
}

// é©åˆ‡ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
export function selectAppropriateVoice(responseType: AIResponseType): string | null {
  if (!shouldPlayVoiceForResponse(responseType, false)) {
    return null // éŸ³å£°å†ç”Ÿãªã—
  }
  
  switch (responseType) {
    case 'encouragement':
      return 'akari_encouragement.wav'
    case 'agreement':  
      return 'akari_agreement.wav'
    case 'emotional_support':
      return 'akari_support.wav'
    case 'thinking':
      return 'akari_thinking.wav'
    default:
      return null // No fallback to default.wav - system should handle gracefully
  }
}

// åŒ…æ‹¬çš„ãªåˆ†æï¼ˆåˆæœŸæŒ¨æ‹¶å¯¾å¿œï¼‰
export function analyzeAiResponseComprehensive(
  aiResponse: string,
  isInitialGreeting: boolean = false
): AIResponseAnalysis {
  if (isInitialGreeting) {
    return createAnalysis('initial_greeting', true, 'akari_greeting.wav', 1.0,
      'Initial greeting always has voice', ['greeting'])
  }
  
  return analyzeAiResponseForVoice(aiResponse)
}

// ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½
export function debugAiResponseVoice(aiResponse: string): void {
  console.log('ğŸ¯ AI Response Voice Analysis Debug')
  console.log('=' .repeat(60))
  
  const analysis = analyzeAiResponseForVoice(aiResponse)
  
  console.log('AI Response:', `"${aiResponse}"`)
  console.log('Detected Type:', analysis.responseType)
  console.log('Should Play Voice:', analysis.shouldPlayVoice ? 'âœ… YES' : 'âŒ NO')
  console.log('Voice File:', analysis.voiceFile || 'None')
  console.log('Confidence:', (analysis.confidence * 100).toFixed(1) + '%')
  console.log('Reasoning:', analysis.reasoning)
  console.log('Detected Patterns:', analysis.detectedPatterns.join(', ') || 'None')
  
  console.log('\nğŸ“‹ All Response Types:')
  const allTypes: AIResponseType[] = [
    'encouragement', 'agreement', 'emotional_support', 'thinking',
    'nutrition_advice', 'food_discussion', 'general_conversation'
  ]
  
  allTypes.forEach(type => {
    const shouldPlay = shouldPlayVoiceForResponse(type, false)
    const voiceFile = selectAppropriateVoice(type)
    console.log(`  ${type}: ${shouldPlay ? 'ğŸµ' : 'ğŸ”‡'} ${voiceFile || 'No voice'}`)
  })
  
  console.log('=' .repeat(60))
}

// ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®Ÿè¡Œ
export function runAiResponseVoiceTests(): void {
  console.log('ğŸ§ª Running AI Response Voice Tests')
  console.log('=' .repeat(60))

  const testCases = [
    {
      response: 'ç´ æ™´ã‚‰ã—ã„æ±ºæ„ã§ã™ã­ï¼ç§ã‚‚å…¨åŠ›ã§ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ï¼',
      expected: 'encouragement',
      expectVoice: true,
      scenario: 'User says "ã‚ã‚ŠãŒã¨ã†é ‘å¼µã‚‹"'
    },
    {
      response: 'ãã°ç¾å‘³ã—ã„ã§ã™ã‚ˆã­ï¼æ „é¤Šé¢ã§ã¯é£Ÿç‰©ç¹Šç¶­ãŒè±Šå¯Œã§...',
      expected: 'food_discussion',
      expectVoice: false,
      scenario: 'User says "ãã°"'
    },
    {
      response: 'ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã‚’1æ—¥60ã‚°ãƒ©ãƒ æ‘‚å–ã—ã€ã‚«ãƒ­ãƒªãƒ¼ã¯1800kcalã‚’ç›®å®‰ã«...',
      expected: 'nutrition_advice', 
      expectVoice: false,
      scenario: 'User asks "ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã—ãŸã„"'
    },
    {
      response: 'ãã†ã§ã™ã­â™ª ãã®æ°—æŒã¡ã‚ˆãã‚ã‹ã‚Šã¾ã™ã€‚',
      expected: 'agreement',
      expectVoice: true,
      scenario: 'User shares feelings'
    },
    {
      response: 'ã†ãƒ¼ã‚“ã€ãã†ã§ã™ã­...',
      expected: 'thinking',
      expectVoice: true,
      scenario: 'AI is thinking'
    }
  ]

  let passedTests = 0

  testCases.forEach((testCase, index) => {
    console.log(`\nTest ${index + 1}: ${testCase.scenario}`)
    const analysis = analyzeAiResponseForVoice(testCase.response)
    
    const typeCorrect = analysis.responseType === testCase.expected
    const voiceCorrect = analysis.shouldPlayVoice === testCase.expectVoice
    
    console.log(`  AI Response: "${testCase.response.substring(0, 40)}..."`)
    console.log(`  Expected: ${testCase.expected} | Voice: ${testCase.expectVoice ? 'ğŸµ' : 'ğŸ”‡'}`)
    console.log(`  Detected: ${analysis.responseType} | Voice: ${analysis.shouldPlayVoice ? 'ğŸµ' : 'ğŸ”‡'}`)
    console.log(`  Type: ${typeCorrect ? 'âœ…' : 'âŒ'} | Voice: ${voiceCorrect ? 'âœ…' : 'âŒ'}`)
    
    if (typeCorrect && voiceCorrect) {
      passedTests++
      console.log('  Result: âœ… PASS')
    } else {
      console.log('  Result: âŒ FAIL')
    }
  })

  console.log(`\nğŸ“Š Test Results: ${passedTests}/${testCases.length} tests passed`)
  if (passedTests === testCases.length) {
    console.log('âœ… ALL TESTS PASSED - AI response voice system working correctly!')
  } else {
    console.error('âŒ SOME TESTS FAILED - AI response voice system needs adjustment')
  }

  console.log('=' .repeat(60))
}

// ===============================================
// ğŸ¯ NutriRoom å¤šæ§˜éŸ³å£°é¸æŠã‚·ã‚¹ãƒ†ãƒ 
// ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæº–æ‹ 16ãƒ‘ã‚¿ãƒ¼ãƒ³éŸ³å£°æ´»ç”¨
// ===============================================

// ã€å¤šæ§˜éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã€‘ResponseTypeå®šç¾©
export type ResponseType = 
  | 'food_chat'      // é£Ÿã¹ç‰©é›‘è«‡ï¼ˆéŸ³å£°ä¸è¦ï¼‰
  | 'emotional_response'  // æ„Ÿæƒ…çš„åå¿œï¼ˆè©³ç´°ãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠï¼‰
  | 'general'        // ä¸€èˆ¬ä¼šè©±ï¼ˆéŸ³å£°ä¸è¦ï¼‰
  | 'initial_greeting' // åˆå›æŒ¨æ‹¶ï¼ˆéŸ³å£°å¿…è¦ï¼‰

// ã€æ–°ã€‘è©³ç´°æ„Ÿæƒ…éŸ³å£°ãƒãƒƒãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
const selectDetailedVoicePattern = (aiResponse: string): string | null => {
  console.log(`=== Detailed Voice Pattern Selection ===`);
  console.log(`Analyzing: "${aiResponse}"`);
  
  // 1. ç§°è³›ãƒ»ç´ æ™´ã‚‰ã—ã„ç³»
  if (aiResponse.includes('ã™ã”ã„') || aiResponse.includes('ç´ æ™´ã‚‰ã—ã„') || 
      aiResponse.includes('æœ¬å½“ã«') || aiResponse.includes('å®Œç’§')) {
    console.log('Selected: akari_great.wav (ç§°è³›)');
    return 'akari_great.wav';
  }
  
  // 2. åŒæ„ãƒ»å…±æ„Ÿç³»
  if (aiResponse.includes('ãã†ã§ã™ã­') || aiResponse.includes('ç§ã‚‚ãã†æ€') || 
      aiResponse.includes('åŒæ„Ÿ') || aiResponse.includes('ãŠã£ã—ã‚ƒã‚‹é€šã‚Š')) {
    console.log('Selected: akari_agreement.wav (åŒæ„ãƒ»å…±æ„Ÿ)');
    return 'akari_agreement.wav';
  }
  
  // 3. æ°—æŒã¡å…±æ„Ÿç³»ï¼ˆç†è§£ã‚ˆã‚Šå„ªå…ˆï¼‰
  if (aiResponse.includes('ãã®æ°—æŒã¡') || aiResponse.includes('æ°—æŒã¡') ||
      (aiResponse.includes('åˆ†ã‹ã‚Šã¾ã™') && aiResponse.includes('æ°—æŒã¡'))) {
    console.log('Selected: akari_empathy.wav (æ°—æŒã¡å…±æ„Ÿ)');
    return 'akari_empathy.wav';
  }
  
  // 4. ç†è§£ãƒ»ç´å¾—ç³»
  if (aiResponse.includes('ãªã‚‹ã»ã©') || aiResponse.includes('å‹‰å¼·ã«ãªã‚Š') || 
      aiResponse.includes('ã‚ˆãåˆ†ã‹ã‚Š') || aiResponse.includes('ç†è§£') ||
      aiResponse.includes('åˆ†ã‹ã‚Šã¾ã™')) {
    console.log('Selected: akari_understanding.wav (ç†è§£ãƒ»ç´å¾—)');
    return 'akari_understanding.wav';
  }
  
  // 5. é©šããƒ»èˆˆå‘³ç³»
  if (aiResponse.includes('ãˆãƒ¼') || aiResponse.includes('ã³ã£ãã‚Š') || 
      aiResponse.includes('ãã†ãªã‚“ã§ã™ã‹') || aiResponse.includes('çŸ¥ã‚‰ãªã‹ã£ãŸ')) {
    console.log('Selected: akari_surprise.wav (é©šããƒ»èˆˆå‘³)');
    return 'akari_surprise.wav';
  }
  
  // 6. åŠªåŠ›èªçŸ¥ç³»
  if (aiResponse.includes('é ‘å¼µã£ã¦') || aiResponse.includes('ãã®èª¿å­') || 
      aiResponse.includes('ã‚ˆãã‚„ã£ã¦') || aiResponse.includes('åŠªåŠ›')) {
    console.log('Selected: akari_effort.wav (åŠªåŠ›èªçŸ¥)');
    return 'akari_effort.wav';
  }
  
  // 7. è‚¯å®šè©•ä¾¡ç³»
  if (aiResponse.includes('ã„ã„ã§ã™ã­') || aiResponse.includes('è‰¯ã„ã¨æ€') || 
      aiResponse.includes('ç´ æ•µ') || aiResponse.includes('ãƒŠã‚¤ã‚¹')) {
    console.log('Selected: akari_nice.wav (è‚¯å®šè©•ä¾¡)');
    return 'akari_nice.wav';
  }
  
  // 8. å¿œæ´ãƒ»åŠ±ã¾ã—ç³»
  if (aiResponse.includes('ä¸€ç·’ã«é ‘å¼µã‚Š') || aiResponse.includes('ãƒ•ã‚¡ã‚¤ãƒˆ') || 
      aiResponse.includes('å¿œæ´') || aiResponse.includes('è² ã‘ãªã„ã§')) {
    console.log('Selected: akari_cheer.wav (å¿œæ´)');
    return 'akari_cheer.wav';
  }
  
  // 9. ã‚µãƒãƒ¼ãƒˆå®£è¨€ç³»
  if (aiResponse.includes('ã‚µãƒãƒ¼ãƒˆ') || aiResponse.includes('ç›¸è«‡') || 
      aiResponse.includes('ã„ã¤ã§ã‚‚') || aiResponse.includes('æ”¯ãˆã¾ã™')) {
    console.log('Selected: akari_support.wav (ã‚µãƒãƒ¼ãƒˆå®£è¨€)');
    return 'akari_support.wav';
  }
  
  // 10. ãƒã‚¸ãƒ†ã‚£ãƒ–ç³»
  if (aiResponse.includes('å¤§ä¸ˆå¤«') || aiResponse.includes('å‰å‘ã') || 
      aiResponse.includes('ãã£ã¨') || aiResponse.includes('æ˜ã‚‹ã')) {
    console.log('Selected: akari_positive.wav (ãƒã‚¸ãƒ†ã‚£ãƒ–)');
    return 'akari_positive.wav';
  }
  
  // 11. æ„Ÿè¬ç³»
  if (aiResponse.includes('ã‚ã‚ŠãŒã¨ã†') || aiResponse.includes('å¬‰ã—ã„') || 
      aiResponse.includes('æ„Ÿè¬') || aiResponse.includes('åŠ©ã‹ã‚Š')) {
    console.log('Selected: akari_thanks.wav (æ„Ÿè¬)');
    return 'akari_thanks.wav';
  }
  
  // 12. ã©ã†ã„ãŸã—ã¾ã—ã¦ç³»
  if (aiResponse.includes('ã©ã†ã„ãŸã—ã¾ã—ã¦') || aiResponse.includes('å½“ç„¶') || 
      aiResponse.includes('ã„ãˆã„ãˆ') || aiResponse.includes('é ¼ã£ã¦')) {
    console.log('Selected: akari_welcome.wav (ã©ã†ã„ãŸã—ã¾ã—ã¦)');
    return 'akari_welcome.wav';
  }
  
  // 13. å®‰å¿ƒãƒ»å•é¡Œãªã—ç³»
  if (aiResponse.includes('å•é¡Œã‚ã‚Šã¾ã›ã‚“') || aiResponse.includes('å¿ƒé…') || 
      aiResponse.includes('å®‰å¿ƒ') || aiResponse.includes('å…¨ç„¶å¤§ä¸ˆå¤«')) {
    console.log('Selected: akari_no_problem.wav (å®‰å¿ƒãƒ»å•é¡Œãªã—)');
    return 'akari_no_problem.wav';
  }
  
  // 14. è€ƒãˆè¾¼ã¿ç³»
  if (aiResponse.includes('ã†ã€œã‚“') || aiResponse.includes('ä¸€ç·’ã«è€ƒãˆ') || 
      aiResponse.includes('ã©ã†ã§ã—ã‚‡ã†') || aiResponse.includes('æ¤œè¨')) {
    console.log('Selected: akari_thinking.wav (è€ƒãˆè¾¼ã¿)');
    return 'akari_thinking.wav';
  }
  
  // 15. è¬ç½ªç³»
  if (aiResponse.includes('ã™ã¿ã¾ã›ã‚“') || aiResponse.includes('ã”ã‚ã‚“') || 
      aiResponse.includes('ç”³ã—è¨³') || aiResponse.includes('æ°—ã‚’ã¤ã‘')) {
    console.log('Selected: akari_sorry.wav (è¬ç½ª)');
    return 'akari_sorry.wav';
  }
  
  console.log('No specific voice pattern matched - using general encouragement');
  return 'akari_encouragement.wav'; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
};

// ã€å¤šæ§˜éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã€‘å¼·åŠ›ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®š
const hasStrongEncouragementKeywords = (aiResponse: string): boolean => {
  const strongKeywords = [
    'ç´ æ™´ã‚‰ã—ã„', 'ã™ã”ã„', 'é ‘å¼µã£ã¦', 'å¿œæ´', 'ã‚µãƒãƒ¼ãƒˆ',
    'æœ¬å½“ã«', 'å®Œç’§', 'æ„Ÿè¬', 'ã‚ã‚ŠãŒã¨ã†', 'å¤§ä¸ˆå¤«'
  ];
  
  return strongKeywords.some(keyword => aiResponse.includes(keyword));
};

// ã€å¤šæ§˜éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã€‘æ„Ÿæƒ…çš„éŸ³å£°å¿…è¦åˆ¤å®š
const shouldHaveEmotionalVoice = (response: string): boolean => {
  const emotionalKeywords = [
    'ãã†ã§ã™ã­', 'ãªã‚‹ã»ã©', 'ã™ã”ã„', 'ã„ã„ã§ã™ã­', 'ã‚ã‹ã‚Šã¾ã™',
    'ã‚ã‚ŠãŒã¨ã†', 'ã³ã£ãã‚Š', 'é ‘å¼µã£ã¦', 'ã‚µãƒãƒ¼ãƒˆ', 'å¤§ä¸ˆå¤«',
    'ç§ã‚‚ãã†æ€', 'åŒæ„Ÿ', 'ç†è§£', 'å…±æ„Ÿ', 'å®‰å¿ƒ', 'æ°—æŒã¡',
    'åˆ†ã‹ã‚Šã¾ã™', 'ä¸€ç·’ã«é ‘å¼µã‚Š', 'ãƒ•ã‚¡ã‚¤ãƒˆ', 'å¿œæ´', 'ç›¸è«‡',
    'ãã®æ°—æŒã¡', 'å‰å‘ã', 'ãã£ã¨', 'å¬‰ã—ã„', 'æ„Ÿè¬'
  ];
  
  return emotionalKeywords.some(keyword => response.includes(keyword));
};

// ã€å¤šæ§˜éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã€‘ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ 
export const analyzeFirstSentenceOnly = (aiResponse: string): ResponseType => {
  const firstSentence = aiResponse.split(/[ï¼ã€‚ï¼Ÿâ™ªâ™¡ğŸ˜Šï½]/)[0];
  
  console.log(`=== Hybrid Voice Analysis ===`);
  console.log(`Full response: "${aiResponse}"`);
  console.log(`First sentence: "${firstSentence}"`);
  
  // é£Ÿã¹ç‰©é›‘è«‡ã‚’æœ€å„ªå…ˆåˆ¤å®šï¼ˆéŸ³å£°ä¸è¦ï¼‰
  if (firstSentence.includes('ãƒãƒ§ã‚³') || 
      firstSentence.includes('ãƒãƒƒã‚­ãƒ¼') || 
      firstSentence.includes('ç¾å‘³ã—ã„') ||
      firstSentence.includes('å¤§å¥½ã') ||
      firstSentence.includes('ãŠè“å­') ||
      firstSentence.includes('é£Ÿã¹ç‰©') ||
      firstSentence.includes('æ–™ç†')) {
    console.log('Food chat detected - Voice DISABLED');
    return 'food_chat';
  }
  
  // å¼·åŠ›ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¾ãŸã¯æ„Ÿæƒ…çš„åå¿œãŒã‚ã‚‹å ´åˆ
  const hasStrongEncouragement = hasStrongEncouragementKeywords(aiResponse);
  const hasEmotionalContent = shouldHaveEmotionalVoice(aiResponse);
  
  if (hasStrongEncouragement || hasEmotionalContent) {
    console.log('Emotional response detected - Detailed voice pattern selection');
    return 'emotional_response';
  }
  
  console.log('General conversation - Voice DISABLED');
  return 'general';
};

// ã€å®Œå…¨æ–°ã‚·ã‚¹ãƒ†ãƒ ã€‘æ™‚é–“ãƒ™ãƒ¼ã‚¹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
function getTimeBasedVoice(): string {
  const hour = new Date().getHours();
  if (hour >= 6 && hour < 12) return 'akari_morning.wav';
  if (hour >= 12 && hour < 18) return 'akari_afternoon.wav';
  if (hour >= 18 && hour < 22) return 'akari_evening.wav';
  return 'akari_late.wav';
}

// ã€å¤šæ§˜éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã€‘æœ€é©éŸ³å£°åˆ¤å®š
const determineOptimalVoice = (aiResponse: string, isInitialGreeting: boolean = false) => {
  console.log(`=== Optimal Voice Determination ===`);
  
  if (isInitialGreeting) {
    console.log('âœ… Initial greeting - Time-based voice');
    return { shouldPlay: true, voiceFile: getTimeBasedVoice() };
  }
  
  const responseType = analyzeFirstSentenceOnly(aiResponse);
  
  switch (responseType) {
    case 'emotional_response':
      // è©³ç´°ãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠã§è±Šã‹ãªæ„Ÿæƒ…è¡¨ç¾
      const detailedVoice = selectDetailedVoicePattern(aiResponse);
      console.log(`âœ… Emotional voice selected: ${detailedVoice}`);
      return { shouldPlay: true, voiceFile: detailedVoice };
      
    case 'food_chat':
    case 'general':
    default:
      console.log('âŒ Regular conversation - Voice DISABLED');
      return { shouldPlay: false, voiceFile: null };
  }
};

// ã€å¤šæ§˜éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã€‘ãƒ¡ã‚¤ãƒ³é–¢æ•°
export const determineVoiceFromAiResponse = (aiResponse: string, isInitialGreeting: boolean = false) => {
  return determineOptimalVoice(aiResponse, isInitialGreeting);
};

// ã€å¤šæ§˜éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã€‘è±Šã‹ãªæ„Ÿæƒ…ãƒ†ã‚¹ãƒˆ
export function runDiverseVoiceTests(): void {
  console.log('ğŸµ Running Diverse Voice System Tests - 16 Patterns');
  console.log('=' .repeat(60));

  const emotionalTestCases = [
    // é£Ÿã¹ç‰©é›‘è«‡ï¼ˆéŸ³å£°ãªã—ï¼‰
    {
      response: 'ãƒãƒ§ã‚³å¤§å¥½ãã€œâ™¡ã‚ã‹ã‚‹ï¼',
      expectedType: 'food_chat',
      expectedVoice: null,
      scenario: 'é£Ÿã¹ç‰©é›‘è«‡ (å•é¡Œã‚±ãƒ¼ã‚¹)'
    },
    {
      response: 'ãƒãƒƒã‚­ãƒ¼ã­ï¼ğŸ˜Š ç¾å‘³ã—ã„ã§ã™ã‚ˆã­...',
      expectedType: 'food_chat',
      expectedVoice: null,
      scenario: 'é£Ÿã¹ç‰©é›‘è«‡'
    },
    
    // ç§°è³›ãƒ»ç´ æ™´ã‚‰ã—ã„ç³»
    {
      response: 'ã™ã”ã„ã§ã™ã­ã€œï¼æœ¬å½“ã«ç´ æ™´ã‚‰ã—ã„ã§ã™â™ª',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_great.wav',
      scenario: 'ç§°è³›ãƒ»ç´ æ™´ã‚‰ã—ã„ç³»'
    },
    
    // åŒæ„ãƒ»å…±æ„Ÿç³»
    {
      response: 'ãã†ã§ã™ã­ã€œâ™ªç§ã‚‚ãã†æ€ã„ã¾ã™ï¼',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_agreement.wav',
      scenario: 'åŒæ„ãƒ»å…±æ„Ÿç³»'
    },
    
    // ç†è§£ãƒ»ç´å¾—ç³»
    {
      response: 'ãªã‚‹ã»ã©ï¼ã¨ã¦ã‚‚å‹‰å¼·ã«ãªã‚Šã¾ã—ãŸã€œ',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_understanding.wav',
      scenario: 'ç†è§£ãƒ»ç´å¾—ç³»'
    },
    
    // é©šããƒ»èˆˆå‘³ç³»
    {
      response: 'ãˆãƒ¼ï¼ãã†ãªã‚“ã§ã™ã‹ï¼Ÿã³ã£ãã‚Šã§ã™ã€œï¼',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_surprise.wav',
      scenario: 'é©šããƒ»èˆˆå‘³ç³»'
    },
    
    // æ°—æŒã¡å…±æ„Ÿç³»
    {
      response: 'ãã®æ°—æŒã¡ã€ã‚ˆãåˆ†ã‹ã‚Šã¾ã™ã€œâ™ª',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_empathy.wav',
      scenario: 'æ°—æŒã¡å…±æ„Ÿç³»'
    },
    
    // åŠªåŠ›èªçŸ¥ç³»
    {
      response: 'é ‘å¼µã£ã¦ã„ã¾ã™ã­ï¼ãã®èª¿å­ã§ã™ã€œâ™ª',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_effort.wav',
      scenario: 'åŠªåŠ›èªçŸ¥ç³»'
    },
    
    // è‚¯å®šè©•ä¾¡ç³»
    {
      response: 'ã„ã„ã§ã™ã­ã€œï¼ã¨ã¦ã‚‚è‰¯ã„ã¨æ€ã„ã¾ã™â™ª',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_nice.wav',
      scenario: 'è‚¯å®šè©•ä¾¡ç³»'
    },
    
    // å¿œæ´ãƒ»åŠ±ã¾ã—ç³»
    {
      response: 'ä¸€ç·’ã«é ‘å¼µã‚Šã¾ã—ã‚‡ã†ï¼ãƒ•ã‚¡ã‚¤ãƒˆâ™ª',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_cheer.wav',
      scenario: 'å¿œæ´ãƒ»åŠ±ã¾ã—ç³»'
    },
    
    // ã‚µãƒãƒ¼ãƒˆå®£è¨€ç³»
    {
      response: 'ã„ã¤ã§ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€œï¼ç›¸è«‡ã—ã¦ãã ã•ã„ã­â™ª',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_support.wav',
      scenario: 'ã‚µãƒãƒ¼ãƒˆå®£è¨€ç³»'
    },
    
    // ãƒã‚¸ãƒ†ã‚£ãƒ–ç³»
    {
      response: 'å¤§ä¸ˆå¤«ã§ã™ã‚ˆï¼ãã£ã¨å‰å‘ãã«ã„ã‘ã¾ã™â™ª',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_positive.wav',
      scenario: 'ãƒã‚¸ãƒ†ã‚£ãƒ–ç³»'
    },
    
    // æ„Ÿè¬ç³»
    {
      response: 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ã¨ã¦ã‚‚å¬‰ã—ã„ã§ã™â™ª',
      expectedType: 'emotional_response',
      expectedVoice: 'akari_thanks.wav',
      scenario: 'æ„Ÿè¬ç³»'
    }
  ];

  let passedTests = 0;

  emotionalTestCases.forEach((testCase, index) => {
    console.log(`\nğŸ­ Test ${index + 1}: ${testCase.scenario}`);
    const result = determineVoiceFromAiResponse(testCase.response, false);
    const detectedType = analyzeFirstSentenceOnly(testCase.response);
    
    const typeCorrect = detectedType === testCase.expectedType;
    const voiceCorrect = result.voiceFile === testCase.expectedVoice;
    const playCorrect = result.shouldPlay === (testCase.expectedVoice !== null);
    
    console.log(`  ğŸ¤ AI Response: "${testCase.response.substring(0, 50)}..."`);
    console.log(`  ğŸ¯ Expected: ${testCase.expectedType} | Voice: ${testCase.expectedVoice || 'None'}`);
    console.log(`  ğŸ” Detected: ${detectedType} | Voice: ${result.voiceFile || 'None'}`);
    console.log(`  ğŸ“Š Type: ${typeCorrect ? 'âœ…' : 'âŒ'} | Voice: ${voiceCorrect ? 'âœ…' : 'âŒ'} | Play: ${playCorrect ? 'âœ…' : 'âŒ'}`);
    
    if (typeCorrect && voiceCorrect && playCorrect) {
      passedTests++;
      console.log('  âœ¨ Result: âœ… PASS - Rich emotional voice experience!');
    } else {
      console.log('  âš ï¸ Result: âŒ FAIL');
      console.log(`  ğŸ“ Debug: shouldPlay=${result.shouldPlay}, voiceFile=${result.voiceFile}`);
    }
  });

  console.log(`\nğŸ“Š Test Results: ${passedTests}/${emotionalTestCases.length} tests passed`);
  if (passedTests === emotionalTestCases.length) {
    console.log('âœ¨ ALL TESTS PASSED - Diverse voice system with 16 patterns working perfectly!');
    console.log('ğŸµ Rich emotional voice experience achieved!');
  } else {
    console.error('âŒ SOME TESTS FAILED - Diverse voice system needs adjustment');
  }

  console.log('=' .repeat(60));
}

// ãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒã§ã®ãƒ‡ãƒãƒƒã‚°é–¢æ•°å…¬é–‹
if (typeof window !== 'undefined') {
  ;(window as unknown as Record<string, unknown>).debugAiResponseVoice = debugAiResponseVoice
  ;(window as unknown as Record<string, unknown>).runAiVoiceTests = runAiResponseVoiceTests
  ;(window as unknown as Record<string, unknown>).analyzeAiResponse = analyzeAiResponseForVoice
  ;(window as unknown as Record<string, unknown>).determineVoiceFromAiResponse = determineVoiceFromAiResponse
  ;(window as unknown as Record<string, unknown>).runDiverseVoiceTests = runDiverseVoiceTests
  ;(window as unknown as Record<string, unknown>).runCompleteSystemTests = runCompleteSystemTests
  ;(window as unknown as Record<string, unknown>).analyzeFirstSentenceOnly = analyzeFirstSentenceOnly
  ;(window as unknown as Record<string, unknown>).selectDetailedVoicePattern = selectDetailedVoicePattern
  
  console.log('ğŸµ NutriRoom Diverse Voice System - 16 Emotional Patterns:')
  console.log('- determineVoiceFromAiResponse(aiResponse) : å¤šæ§˜éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°åˆ¤å®š')
  console.log('- runDiverseVoiceTests() : å¤šæ§˜éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ')
  console.log('- selectDetailedVoicePattern(aiResponse) : 16ãƒ‘ã‚¿ãƒ¼ãƒ³è©³ç´°é¸æŠ')
  console.log('- analyzeFirstSentenceOnly(aiResponse) : ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†æ')
  console.log('')
  console.log('âœ¨ Rich Voice Patterns Available:')
  console.log('akari_great.wav, akari_agreement.wav, akari_understanding.wav,')
  console.log('akari_surprise.wav, akari_empathy.wav, akari_effort.wav,')
  console.log('akari_nice.wav, akari_cheer.wav, akari_support.wav,')
  console.log('akari_positive.wav, akari_thanks.wav, akari_welcome.wav,')
  console.log('akari_no_problem.wav, akari_thinking.wav, akari_sorry.wav + time-based voices')
  console.log('')
  console.log('ğŸ”§ Legacy Debug Functions (for comparison):')
  console.log('- debugAiResponseVoice(aiResponse) : ãƒ¬ã‚¬ã‚·ãƒ¼éŸ³å£°åˆ†æ')
  console.log('- runAiVoiceTests() : ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ†ã‚¹ãƒˆ')
  console.log('- analyzeAiResponse(aiResponse) : ãƒ¬ã‚¬ã‚·ãƒ¼è©³ç´°åˆ†æ')
}

// ã€äº’æ›æ€§ç¶­æŒã€‘æ—§é–¢æ•°åã§ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
export const runCompleteSystemTests = runDiverseVoiceTests;