// ğŸ¯ NutriRoom AIè¿”ç­”ãƒ™ãƒ¼ã‚¹éŸ³å£°åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ  - ã‚ˆã‚Šæ­£ç¢ºã§ä¸€è²«ã—ãŸéŸ³å£°é¸æŠ

export type AIResponseType = 
  | 'encouragement'          // åŠ±ã¾ã—ãƒ»ã‚µãƒãƒ¼ãƒˆ
  | 'agreement'              // å…±æ„Ÿãƒ»ã‚ã„ã¥ã¡
  | 'emotional_support'      // æ„Ÿæƒ…ã‚µãƒãƒ¼ãƒˆ
  | 'nutrition_advice'       // æ „é¤Šã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆå°‚é–€çš„ï¼‰
  | 'food_discussion'        // é£Ÿã¹ç‰©é›‘è«‡
  | 'general_conversation'   // ä¸€èˆ¬ä¼šè©±
  | 'initial_greeting'       // åˆæœŸæŒ¨æ‹¶
  | 'thinking'               // è€ƒãˆã¦ã„ã‚‹è¡¨ç¾

export interface AIResponseAnalysis {
  responseType: AIResponseType
  shouldPlayVoice: boolean
  voiceFile?: string
  confidence: number
  reasoning: string
  detectedPatterns: string[]
}

// ã€æ ¸å¿ƒæ©Ÿèƒ½ã€‘AIè¿”ç­”è§£æã«ã‚ˆã‚‹éŸ³å£°åˆ¤å®š - ç²¾åº¦å‘ä¸Šç‰ˆ
export function analyzeAiResponseForVoice(aiResponse: string): AIResponseAnalysis {
  console.log(`ğŸ¯ Analyzing AI response for voice: "${aiResponse.substring(0, 50)}..."`)
  
  const response = aiResponse.toLowerCase()
  const detectedPatterns: string[] = []
  
  // ã€å„ªå…ˆåº¦1ã€‘æœ¬ç‰©ã®åŠ±ã¾ã—ãƒ»æ„Ÿæƒ…ã‚µãƒãƒ¼ãƒˆï¼ˆå³æ ¼åˆ¤å®šï¼‰
  const genuineEncouragementPatterns = [
    'ç´ æ™´ã‚‰ã—ã„æ±ºæ„', 'å…¨åŠ›ã§ã‚µãƒãƒ¼ãƒˆ', 'ä¸€ç·’ã«é ‘å¼µã‚Š', 'å¿œæ´ã—ã¾ã™',
    'å¤§ä¸ˆå¤«ã§ã™', 'å®‰å¿ƒã—ã¦ãã ã•ã„', 'ãã£ã¨ã§ãã¾ã™', 'è² ã‘ãªã„ã§',
    'ãƒ•ã‚¡ã‚¤ãƒˆ', 'ã‚ãªãŸãªã‚‰', 'ç§ãŒæ”¯ãˆã¾ã™', 'åŠ±ã¾ã—', 'é ‘å¼µã£ã¦',
    'å¿œæ´ã—', 'æ”¯æ´ã—', 'ã‚µãƒãƒ¼ãƒˆã—', 'å¯„ã‚Šæ·»ã„', 'ä¸€ç·’ã«ä¹—ã‚Šè¶Šãˆ'
  ]
  
  const foundGenuineEncouragement = genuineEncouragementPatterns.filter(pattern => response.includes(pattern))
  if (foundGenuineEncouragement.length > 0) {
    detectedPatterns.push(...foundGenuineEncouragement)
    console.log('âœ… AI response type: genuine_encouragement (voice enabled)')
    return createAnalysis('encouragement', true, 'akari_encouragement.wav', 0.95, 
      'AI response contains genuine encouragement/emotional support', detectedPatterns)
  }
  
  // ã€å„ªå…ˆåº¦2ã€‘é£Ÿã¹ç‰©ã«ã¤ã„ã¦ã®é›‘è«‡ãƒ»å…±æ„Ÿï¼ˆéŸ³å£°ä¸è¦ï¼‰
  const foodDiscussionPatterns = [
    'ç¾å‘³ã—ã„', 'å¥½ã', 'é£Ÿã¹', 'æ–™ç†', 'å‘³', 'é¦™ã‚Š', 'ã§ã™ã‚ˆã­',
    'ãƒ¬ã‚·ãƒ”', 'ä½œã‚Šæ–¹', 'é£Ÿæ„Ÿ', 'æ—¬', 'å­£ç¯€', 'ãŠã™ã™ã‚',
    'ã„ã„ã§ã™ã­', 'ãã†ã§ã™ã­', 'çŸ¥ã£ã¦ã¾ã™', 'äººæ°—', 'å®šç•ª',
    'èª¿ç†', 'ææ–™', 'é£Ÿæ', 'é¢¨å‘³', 'é£Ÿã¹æ–¹', 'ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆ',
    'æ¸©ã‹ã„', 'å†·ãŸã„', 'ç”˜ã„', 'è¾›ã„', 'é…¸ã£ã±ã„', 'ãƒãƒƒã‚­ãƒ¼'
  ]
  
  const foundFood = foodDiscussionPatterns.filter(pattern => response.includes(pattern))
  if (foundFood.length > 0) {
    detectedPatterns.push(...foundFood)
    console.log('âŒ AI response type: food_discussion (text-only - casual food talk)')
    return createAnalysis('food_discussion', false, undefined, 0.9,
      'AI response is casual food discussion - text-only appropriate', detectedPatterns)
  }
  
  // ã€å„ªå…ˆåº¦3ã€‘é‡è¦ãªå…±æ„Ÿãƒ»ç†è§£ï¼ˆé£Ÿã¹ç‰©æ–‡è„ˆä»¥å¤–ã§ã®æ·±ã„ç†è§£ï¼‰
  const deepAgreementPatterns = [
    'ã‚ˆãç†è§£', 'æ°—æŒã¡', 'ã‚ˆãã‚ã‹ã‚Š', 'ãã†ãªã‚“ã§ã™',
    'ã‚ã‹ã‚‹', 'ç†è§£ã§ã', 'å…±æ„Ÿ', 'ãã®æ°—æŒã¡', 'ãŠã£ã—ã‚ƒã‚‹é€šã‚Š'
  ]
  
  const foundDeepAgreement = deepAgreementPatterns.filter(pattern => response.includes(pattern))
  if (foundDeepAgreement.length > 0) {
    detectedPatterns.push(...foundDeepAgreement)
    console.log('âœ… AI response type: deep_agreement (voice enabled)')
    return createAnalysis('agreement', true, 'akari_agreement.wav', 0.85,
      'AI response shows deep understanding/empathy', detectedPatterns)
  }
  
  // ã€å„ªå…ˆåº¦4ã€‘è»½ã„å…±æ„Ÿãƒ»ã‚ã„ã¥ã¡ï¼ˆé£Ÿã¹ç‰©æ–‡è„ˆãƒã‚§ãƒƒã‚¯ï¼‰
  const lightAgreementPatterns = [
    'ãã†ã§ã™ã­', 'ãªã‚‹ã»ã©', 'ã„ã„ã§ã™ã­', 'ã‚ã‹ã‚Šã¾ã™', 'åˆ†ã‹ã‚Šã¾ã™', 'åŒæ„Ÿ', 'ãã®é€šã‚Š'
  ]
  
  const foundLightAgreement = lightAgreementPatterns.filter(pattern => response.includes(pattern))
  if (foundLightAgreement.length > 0) {
    // é£Ÿã¹ç‰©æ–‡è„ˆã§ã®è»½ã„å…±æ„Ÿã¯ food_discussion ã¨ã—ã¦æ‰±ã†
    const isFoodContext = response.includes('ç¾å‘³ã—ã„') || 
                         response.includes('é£Ÿã¹') || 
                         response.includes('æ–™ç†') ||
                         response.includes('å‘³') ||
                         response.includes('å¥½ã')
    
    if (isFoodContext) {
      detectedPatterns.push(...foundLightAgreement, 'food_context')
      console.log('âŒ AI response type: food_discussion (light agreement in food context)')
      return createAnalysis('food_discussion', false, undefined, 0.8,
        'Light agreement in food context - text-only appropriate', detectedPatterns)
    } else {
      detectedPatterns.push(...foundLightAgreement)
      console.log('âœ… AI response type: light_agreement (voice enabled)')
      return createAnalysis('agreement', true, 'akari_agreement.wav', 0.75,
        'AI response shows light agreement/acknowledgment', detectedPatterns)
    }
  }
  
  // ã€å„ªå…ˆåº¦5ã€‘æ·±åˆ»ãªæ„Ÿæƒ…çš„ã‚µãƒãƒ¼ãƒˆï¼ˆé‡è¦ãªæ„Ÿæƒ…çŠ¶æ³ã§ã®æ”¯æ´ï¼‰
  const emotionalSupportPatterns = [
    'å…ƒæ°—å‡ºã—ã¦', 'æ¥½ã—ã„æ°—æŒã¡', 'å¬‰ã—ã„æ°—æŒã¡', 'å–œã³', 'å¹¸ã›',
    'è½ã¡è¾¼ã‚“ã§', 'æ‚²ã—ã„', 'è¾›ã„', 'å¤§å¤‰', 'å›°é›£',
    'ä¹—ã‚Šè¶Šãˆ', 'å…‹æœ', 'å‰å‘ã', 'ãƒã‚¸ãƒ†ã‚£ãƒ–',
    'å¯„ã‚Šæ·»', 'å´ã«ã„', 'ç†è§£ã—ã¾ã™', 'å¿ƒé…ã—ãªã„ã§'
  ]
  
  const foundEmotional = emotionalSupportPatterns.filter(pattern => response.includes(pattern))
  if (foundEmotional.length > 0) {
    detectedPatterns.push(...foundEmotional)
    console.log('âœ… AI response type: emotional_support (voice enabled)')
    return createAnalysis('emotional_support', true, 'akari_support.wav', 0.8,
      'AI response provides important emotional support', detectedPatterns)
  }
  
  // ã€å„ªå…ˆåº¦6ã€‘æ „é¤Šãƒ»å¥åº·ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç³»ï¼ˆå°‚é–€çš„ãªèª¬æ˜ - éŸ³å£°ãªã—ï¼‰
  const nutritionAdvicePatterns = [
    'ã‚¿ãƒ³ãƒ‘ã‚¯è³ª', 'ãƒ“ã‚¿ãƒŸãƒ³', 'ã‚«ãƒ­ãƒªãƒ¼', 'æ „é¤Šç´ ', 'ãƒŸãƒãƒ©ãƒ«',
    'é£Ÿç‰©ç¹Šç¶­', 'ç‚­æ°´åŒ–ç‰©', 'è„‚è³ª', 'ãƒãƒ©ãƒ³ã‚¹', 'æ‘‚å–',
    'åŠ¹æœ', 'æˆåˆ†', 'å«ã¾ã‚Œ', 'è±Šå¯Œ', 'æ¨å¥¨',
    '1æ—¥', 'ã‚°ãƒ©ãƒ ', 'ç›®å®‰', 'å¿…è¦é‡', 'ä¸è¶³',
    'éå‰°', 'é©é‡', 'ä»£è¬', 'æ¶ˆåŒ–', 'å¸å'
  ]
  
  const foundNutrition = nutritionAdvicePatterns.filter(pattern => response.includes(pattern))
  if (foundNutrition.length >= 2) { // è¤‡æ•°ã®å°‚é–€ç”¨èªãŒå«ã¾ã‚Œã‚‹å ´åˆ
    detectedPatterns.push(...foundNutrition)
    console.log('âŒ AI response type: nutrition_advice (text-only - professional info)')
    return createAnalysis('nutrition_advice', false, undefined, 0.85,
      'AI response contains detailed nutritional information', detectedPatterns)
  }
  
  // è€ƒãˆã¦ã„ã‚‹è¡¨ç¾ï¼ˆçŸ­ã„ã‚ã„ã¥ã¡çš„ãªéŸ³å£°ï¼‰
  const thinkingPatterns = [
    'ã†ãƒ¼ã‚“', 'ãã†ã§ã™ã­...', 'è€ƒãˆã¦', 'ã©ã†ã§ã—ã‚‡ã†',
    'ã¡ã‚‡ã£ã¨', 'å°‘ã—', 'ã¾ã‚', 'ã†ã‚“'
  ]
  
  const foundThinking = thinkingPatterns.filter(pattern => response.includes(pattern))
  if (foundThinking.length > 0 && aiResponse.length < 30) {
    detectedPatterns.push(...foundThinking)
    console.log('âœ… AI response type: thinking (voice enabled - short)')
    return createAnalysis('thinking', true, 'akari_thinking.wav', 0.7,
      'AI response is short thinking expression', detectedPatterns)
  }
  
  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šä¸€èˆ¬ä¼šè©±ï¼ˆéŸ³å£°ãªã—ï¼‰
  console.log('âŒ AI response type: general_conversation (text-only)')
  return createAnalysis('general_conversation', false, undefined, 0.6,
    'AI response is general conversation', detectedPatterns)
}

// åˆ†æçµæœä½œæˆãƒ˜ãƒ«ãƒ‘ãƒ¼
function createAnalysis(
  type: AIResponseType, 
  shouldPlay: boolean, 
  voiceFile: string | undefined,
  confidence: number,
  reasoning: string,
  patterns: string[]
): AIResponseAnalysis {
  return {
    responseType: type,
    shouldPlayVoice: shouldPlay,
    voiceFile,
    confidence,
    reasoning,
    detectedPatterns: patterns
  }
}

// ã€æ”¹å–„ç‰ˆã€‘éŸ³å£°å†ç”Ÿåˆ¤å®šï¼ˆAIè¿”ç­”ãƒ™ãƒ¼ã‚¹ï¼‰
export function shouldPlayVoiceForResponse(
  responseType: AIResponseType, 
  isInitialGreeting: boolean
): boolean {
  console.log(`=== Voice Decision (AI Response Based) ===`)
  console.log(`Response type: ${responseType}`)
  console.log(`Is initial greeting: ${isInitialGreeting}`)
  
  if (isInitialGreeting) {
    console.log('âœ… Voice enabled: Initial greeting')
    return true
  }
  
  switch (responseType) {
    case 'encouragement':        // åŠ±ã¾ã—ãƒ»ã‚µãƒãƒ¼ãƒˆ
    case 'agreement':           // å…±æ„Ÿãƒ»ã‚ã„ã¥ã¡
    case 'emotional_support':   // æ„Ÿæƒ…ã‚µãƒãƒ¼ãƒˆ
    case 'thinking':            // è€ƒãˆã¦ã„ã‚‹ï¼ˆçŸ­ã„ï¼‰
      console.log(`âœ… Voice enabled: ${responseType} (emotional connection)`)
      return true
      
    case 'nutrition_advice':    // æ „é¤Šã‚¢ãƒ‰ãƒã‚¤ã‚¹
    case 'food_discussion':     // é£Ÿã¹ç‰©é›‘è«‡
    case 'general_conversation': // ä¸€èˆ¬ä¼šè©±
      console.log(`âŒ Voice disabled: ${responseType} (text-only appropriate)`)
      return false
      
    default:
      console.log(`âŒ Voice disabled: Unknown type ${responseType}`)
      return false
  }
}

// é©åˆ‡ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
export function selectAppropriateVoice(responseType: AIResponseType): string | null {
  if (!shouldPlayVoiceForResponse(responseType, false)) {
    return null // éŸ³å£°å†ç”Ÿãªã—
  }
  
  switch (responseType) {
    case 'encouragement':
      return 'akari_encouragement.wav'
    case 'agreement':  
      return 'akari_agreement.wav'
    case 'emotional_support':
      return 'akari_support.wav'
    case 'thinking':
      return 'akari_thinking.wav'
    default:
      return null // No fallback to default.wav - system should handle gracefully
  }
}

// åŒ…æ‹¬çš„ãªåˆ†æï¼ˆåˆæœŸæŒ¨æ‹¶å¯¾å¿œï¼‰
export function analyzeAiResponseComprehensive(
  aiResponse: string,
  isInitialGreeting: boolean = false
): AIResponseAnalysis {
  if (isInitialGreeting) {
    return createAnalysis('initial_greeting', true, 'akari_greeting.wav', 1.0,
      'Initial greeting always has voice', ['greeting'])
  }
  
  return analyzeAiResponseForVoice(aiResponse)
}

// ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½
export function debugAiResponseVoice(aiResponse: string): void {
  console.log('ğŸ¯ AI Response Voice Analysis Debug')
  console.log('=' .repeat(60))
  
  const analysis = analyzeAiResponseForVoice(aiResponse)
  
  console.log('AI Response:', `"${aiResponse}"`)
  console.log('Detected Type:', analysis.responseType)
  console.log('Should Play Voice:', analysis.shouldPlayVoice ? 'âœ… YES' : 'âŒ NO')
  console.log('Voice File:', analysis.voiceFile || 'None')
  console.log('Confidence:', (analysis.confidence * 100).toFixed(1) + '%')
  console.log('Reasoning:', analysis.reasoning)
  console.log('Detected Patterns:', analysis.detectedPatterns.join(', ') || 'None')
  
  console.log('\nğŸ“‹ All Response Types:')
  const allTypes: AIResponseType[] = [
    'encouragement', 'agreement', 'emotional_support', 'thinking',
    'nutrition_advice', 'food_discussion', 'general_conversation'
  ]
  
  allTypes.forEach(type => {
    const shouldPlay = shouldPlayVoiceForResponse(type, false)
    const voiceFile = selectAppropriateVoice(type)
    console.log(`  ${type}: ${shouldPlay ? 'ğŸµ' : 'ğŸ”‡'} ${voiceFile || 'No voice'}`)
  })
  
  console.log('=' .repeat(60))
}

// ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®Ÿè¡Œ
export function runAiResponseVoiceTests(): void {
  console.log('ğŸ§ª Running AI Response Voice Tests')
  console.log('=' .repeat(60))

  const testCases = [
    {
      response: 'ç´ æ™´ã‚‰ã—ã„æ±ºæ„ã§ã™ã­ï¼ç§ã‚‚å…¨åŠ›ã§ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ï¼',
      expected: 'encouragement',
      expectVoice: true,
      scenario: 'User says "ã‚ã‚ŠãŒã¨ã†é ‘å¼µã‚‹"'
    },
    {
      response: 'ãã°ç¾å‘³ã—ã„ã§ã™ã‚ˆã­ï¼æ „é¤Šé¢ã§ã¯é£Ÿç‰©ç¹Šç¶­ãŒè±Šå¯Œã§...',
      expected: 'food_discussion',
      expectVoice: false,
      scenario: 'User says "ãã°"'
    },
    {
      response: 'ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã‚’1æ—¥60ã‚°ãƒ©ãƒ æ‘‚å–ã—ã€ã‚«ãƒ­ãƒªãƒ¼ã¯1800kcalã‚’ç›®å®‰ã«...',
      expected: 'nutrition_advice', 
      expectVoice: false,
      scenario: 'User asks "ãƒ€ã‚¤ã‚¨ãƒƒãƒˆã—ãŸã„"'
    },
    {
      response: 'ãã†ã§ã™ã­â™ª ãã®æ°—æŒã¡ã‚ˆãã‚ã‹ã‚Šã¾ã™ã€‚',
      expected: 'agreement',
      expectVoice: true,
      scenario: 'User shares feelings'
    },
    {
      response: 'ã†ãƒ¼ã‚“ã€ãã†ã§ã™ã­...',
      expected: 'thinking',
      expectVoice: true,
      scenario: 'AI is thinking'
    }
  ]

  let passedTests = 0

  testCases.forEach((testCase, index) => {
    console.log(`\nTest ${index + 1}: ${testCase.scenario}`)
    const analysis = analyzeAiResponseForVoice(testCase.response)
    
    const typeCorrect = analysis.responseType === testCase.expected
    const voiceCorrect = analysis.shouldPlayVoice === testCase.expectVoice
    
    console.log(`  AI Response: "${testCase.response.substring(0, 40)}..."`)
    console.log(`  Expected: ${testCase.expected} | Voice: ${testCase.expectVoice ? 'ğŸµ' : 'ğŸ”‡'}`)
    console.log(`  Detected: ${analysis.responseType} | Voice: ${analysis.shouldPlayVoice ? 'ğŸµ' : 'ğŸ”‡'}`)
    console.log(`  Type: ${typeCorrect ? 'âœ…' : 'âŒ'} | Voice: ${voiceCorrect ? 'âœ…' : 'âŒ'}`)
    
    if (typeCorrect && voiceCorrect) {
      passedTests++
      console.log('  Result: âœ… PASS')
    } else {
      console.log('  Result: âŒ FAIL')
    }
  })

  console.log(`\nğŸ“Š Test Results: ${passedTests}/${testCases.length} tests passed`)
  if (passedTests === testCases.length) {
    console.log('âœ… ALL TESTS PASSED - AI response voice system working correctly!')
  } else {
    console.error('âŒ SOME TESTS FAILED - AI response voice system needs adjustment')
  }

  console.log('=' .repeat(60))
}

// ===============================================
// ğŸ¯ NutriRoom éŸ³å£°åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ç°¡ç´ åŒ–ç‰ˆ
// AIå¿œç­”ä¸€æ–‡ç›®ãƒ™ãƒ¼ã‚¹åˆ¤å®š
// ===============================================

// ä¸€æ–‡ç›®æŠ½å‡ºæ©Ÿèƒ½
const extractFirstSentence = (aiResponse: string): string => {
  // å¥èª­ç‚¹ã‚„æ„Ÿå˜†ç¬¦ã§æœ€åˆã®æ–‡ã‚’åˆ‡ã‚Šå‡ºã—
  const firstSentence = aiResponse.split(/[ï¼ã€‚ï¼Ÿâ™ªâ™¡ğŸ˜Š]/)[0] + 
                       (aiResponse.match(/[ï¼ã€‚ï¼Ÿâ™ªâ™¡ğŸ˜Š]/) || [''])[0];
  
  console.log(`Original response: "${aiResponse}"`);
  console.log(`First sentence extracted: "${firstSentence}"`);
  
  return firstSentence;
};

// ä¸€æ–‡ç›®ãƒ™ãƒ¼ã‚¹éŸ³å£°åˆ¤å®š
const analyzeFirstSentenceForVoice = (firstSentence: string): AIResponseType => {
  console.log(`Analyzing first sentence: "${firstSentence}"`);
  
  // æœ¬å½“ã®åŠ±ã¾ã—ãƒ»é‡è¦ãªåå¿œï¼ˆéŸ³å£°å¿…è¦ï¼‰
  const encouragementStarters = [
    'ç´ æ™´ã‚‰ã—ã„', 'ã™ã”ã„', 'é ‘å¼µã£ã¦', 'å¿œæ´', 'ã‚µãƒãƒ¼ãƒˆ',
    'ãã£ã¨å¤§ä¸ˆå¤«', 'å®‰å¿ƒã—ã¦', 'ãã®èª¿å­', 'ãƒ•ã‚¡ã‚¤ãƒˆ'
  ];
  
  if (encouragementStarters.some(pattern => firstSentence.includes(pattern))) {
    console.log('First sentence type: encouragement (voice enabled)');
    return 'encouragement';
  }
  
  // ã‚ã„ã¥ã¡ãƒ»çŸ­ã„å…±æ„Ÿï¼ˆçŸ­ã„éŸ³å£°ï¼‰
  const agreementStarters = [
    'ãã†ã§ã™ã­', 'ãªã‚‹ã»ã©', 'ã‚ã‹ã‚Šã¾ã™', 'ã„ã„ã§ã™ã­',
    'ãã†ãã†', 'ã†ã‚“ã†ã‚“', 'ãã®ã¨ãŠã‚Š'
  ];
  
  if (agreementStarters.some(pattern => firstSentence.includes(pattern))) {
    console.log('First sentence type: agreement (short voice)');
    return 'agreement';
  }
  
  // è»½ã„åå¿œãƒ»é›‘è«‡ï¼ˆéŸ³å£°ä¸è¦ï¼‰
  const casualStarters = [
    'ãƒãƒƒã‚­ãƒ¼', 'ç¾å‘³ã—ã„', 'å¥½ã', 'çŸ¥ã£ã¦ã‚‹', 'ã‚ãƒ¼',
    'ã­', 'ã ', 'ã§ã™', 'ã§ã™ã‹'
  ];
  
  if (casualStarters.some(pattern => firstSentence.includes(pattern))) {
    console.log('First sentence type: casual_chat (text-only)');
    return 'food_discussion'; // Using existing type for casual chat
  }
  
  console.log('First sentence type: general_conversation (text-only)');
  return 'general_conversation';
};

// ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®ç°¡ç´ åŒ–
export const determineVoiceFromAiResponse = (aiResponse: string, isInitialGreeting: boolean = false) => {
  // åˆå›æŒ¨æ‹¶ã¯å¿…ãšéŸ³å£°
  if (isInitialGreeting) {
    console.log('Voice enabled: Initial greeting');
    return { shouldPlay: true, type: 'initial_greeting' };
  }
  
  // ä¸€æ–‡ç›®ã®ã¿ã§åˆ¤å®š
  const firstSentence = extractFirstSentence(aiResponse);
  const responseType = analyzeFirstSentenceForVoice(firstSentence);
  
  const shouldPlay = ['encouragement', 'agreement'].includes(responseType);
  
  console.log(`=== Simple Voice Decision ===`);
  console.log(`First sentence: "${firstSentence}"`);
  console.log(`Type: ${responseType}`);
  console.log(`Voice: ${shouldPlay ? 'ENABLED' : 'DISABLED'}`);
  console.log(`============================`);
  
  return { shouldPlay, type: responseType };
};

// ç°¡ç´ åŒ–ç‰ˆãƒ†ã‚¹ãƒˆ
export function runSimplifiedVoiceTests(): void {
  console.log('ğŸ§ª Running Simplified Voice Tests');
  console.log('=' .repeat(60));

  const testCases = [
    {
      response: 'ãƒãƒƒã‚­ãƒ¼ã­ï¼ğŸ˜Š ã‚ã‹ã‚‹ã€œï¼ç§ã‚‚å¤§å¥½ãâ™¡...',
      expected: 'food_discussion',
      expectVoice: false,
      scenario: 'Casual food chat'
    },
    {
      response: 'ç´ æ™´ã‚‰ã—ã„æ±ºæ„ã§ã™ã­ï¼ç§ã‚‚å¿œæ´ã—ã¾ã™...',
      expected: 'encouragement',
      expectVoice: true,
      scenario: 'Genuine encouragement'
    },
    {
      response: 'ãã†ã§ã™ã­ã€œâ™ªã¨ã¦ã‚‚è‰¯ã„ã¨æ€ã„ã¾ã™...',
      expected: 'agreement',
      expectVoice: true,
      scenario: 'Agreement response'
    },
    {
      response: 'ç¾å‘³ã—ã„ã§ã™ã‚ˆã­ï¼æ „é¤Šä¾¡ã‚‚é«˜ãã¦...',
      expected: 'food_discussion',
      expectVoice: false,
      scenario: 'Food discussion'
    }
  ];

  let passedTests = 0;

  testCases.forEach((testCase, index) => {
    console.log(`\nTest ${index + 1}: ${testCase.scenario}`);
    const result = determineVoiceFromAiResponse(testCase.response, false);
    
    const typeCorrect = result.type === testCase.expected;
    const voiceCorrect = result.shouldPlay === testCase.expectVoice;
    
    console.log(`  AI Response: "${testCase.response.substring(0, 40)}..."`);
    console.log(`  Expected: ${testCase.expected} | Voice: ${testCase.expectVoice ? 'ğŸµ' : 'ğŸ”‡'}`);
    console.log(`  Detected: ${result.type} | Voice: ${result.shouldPlay ? 'ğŸµ' : 'ğŸ”‡'}`);
    console.log(`  Type: ${typeCorrect ? 'âœ…' : 'âŒ'} | Voice: ${voiceCorrect ? 'âœ…' : 'âŒ'}`);
    
    if (typeCorrect && voiceCorrect) {
      passedTests++;
      console.log('  Result: âœ… PASS');
    } else {
      console.log('  Result: âŒ FAIL');
    }
  });

  console.log(`\nğŸ“Š Test Results: ${passedTests}/${testCases.length} tests passed`);
  if (passedTests === testCases.length) {
    console.log('âœ… ALL TESTS PASSED - Simplified voice system working correctly!');
  } else {
    console.error('âŒ SOME TESTS FAILED - Simplified voice system needs adjustment');
  }

  console.log('=' .repeat(60));
}

// ãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒã§ã®ãƒ‡ãƒãƒƒã‚°é–¢æ•°å…¬é–‹
if (typeof window !== 'undefined') {
  ;(window as unknown as Record<string, unknown>).debugAiResponseVoice = debugAiResponseVoice
  ;(window as unknown as Record<string, unknown>).runAiVoiceTests = runAiResponseVoiceTests
  ;(window as unknown as Record<string, unknown>).analyzeAiResponse = analyzeAiResponseForVoice
  ;(window as unknown as Record<string, unknown>).determineVoiceFromAiResponse = determineVoiceFromAiResponse
  ;(window as unknown as Record<string, unknown>).runSimplifiedVoiceTests = runSimplifiedVoiceTests
  
  console.log('ğŸ¯ AI Response Voice Controller Debug Functions Available:')
  console.log('- debugAiResponseVoice(aiResponse) : AIè¿”ç­”éŸ³å£°åˆ†æ')
  console.log('- runAiVoiceTests() : AIè¿”ç­”éŸ³å£°ãƒ†ã‚¹ãƒˆ')
  console.log('- analyzeAiResponse(aiResponse) : AIè¿”ç­”è©³ç´°åˆ†æ')
  console.log('- determineVoiceFromAiResponse(aiResponse) : ç°¡ç´ åŒ–ç‰ˆéŸ³å£°åˆ¤å®š')
  console.log('- runSimplifiedVoiceTests() : ç°¡ç´ åŒ–ç‰ˆãƒ†ã‚¹ãƒˆ')
}