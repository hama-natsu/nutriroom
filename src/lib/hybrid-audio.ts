// ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ï¼ˆElevenLabs + éŒ²éŸ³éŸ³å£°ï¼‰

import { TimeSlot, getCurrentTimeSlot, getTimeSlotGreeting } from './time-greeting';
import { generateVoice } from './audio-utils';

export interface HybridGreetingConfig {
  character: 'akari'; // ç¾åœ¨ã¯ã‚ã‹ã‚Šã®ã¿å¯¾å¿œ
  userName?: string;
  timeSlot?: TimeSlot; // æŒ‡å®šãªã—ã®å ´åˆã¯è‡ªå‹•åˆ¤å®š
}

export class HybridAudioEngine {
  private baseAudioPath = '/audio/recorded';

  // ãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰éŸ³å£°ç”Ÿæˆ
  async generateHybridGreeting(config: HybridGreetingConfig): Promise<Blob> {
    const timeSlot = config.timeSlot || getCurrentTimeSlot();
    
    console.log('ğŸµ Hybrid Audio Generation:', {
      character: config.character,
      userName: config.userName,
      timeSlot,
      greeting: getTimeSlotGreeting(timeSlot)
    });

    try {
      const audioParts: Blob[] = [];

      // 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒã‚ã‚‹å ´åˆï¼šElevenLabsã§åå‰èª­ã¿ä¸Šã’
      if (config.userName) {
        console.log('ğŸ¤ Generating name part with ElevenLabs...');
        const namePart = await this.generateNamePart(config.userName, config.character);
        audioParts.push(namePart);
        
        // çŸ­ã„ç„¡éŸ³ã‚’è¿½åŠ ï¼ˆè‡ªç„¶ãªé–“ã‚’ä½œã‚‹ï¼‰
        const silence = await this.generateSilence(0.1); // 100ms
        audioParts.push(silence);
      }

      // 2. éŒ²éŸ³éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
      console.log('ğŸµ Loading recorded greeting...');
      const recordedPart = await this.loadRecordedGreeting(config.character, timeSlot);
      audioParts.push(recordedPart);

      // 3. éŸ³å£°ã‚’é€£çµ
      console.log('ğŸ”— Combining audio parts...');
      const finalAudio = await this.combineAudioBlobs(audioParts);
      
      console.log('âœ… Hybrid audio generation completed:', {
        totalParts: audioParts.length,
        finalSize: finalAudio.size
      });
      
      return finalAudio;

    } catch (error) {
      console.error('âŒ Hybrid audio generation failed:', error);
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šElevenLabsã§å…¨æ–‡ç”Ÿæˆ
      return this.generateFallbackAudio(config, timeSlot);
    }
  }

  // ElevenLabsã§ãƒ¦ãƒ¼ã‚¶ãƒ¼åèª­ã¿ä¸Šã’
  private async generateNamePart(userName: string, character: string): Promise<Blob> {
    // åå‰ã«ã€Œã€ã€ã‚’ä»˜ã‘ã¦è‡ªç„¶ãªåŒºåˆ‡ã‚Šã«ã™ã‚‹
    const nameText = `${userName}ã€`;
    
    console.log('ğŸ¤ Generating name with ElevenLabs:', nameText);
    
    try {
      return await generateVoice(nameText, character);
    } catch (error) {
      console.error('âŒ Name generation failed:', error);
      throw error;
    }
  }

  // éŒ²éŸ³éŸ³å£°èª­ã¿è¾¼ã¿
  private async loadRecordedGreeting(character: string, timeSlot: TimeSlot): Promise<Blob> {
    const audioPath = `${this.baseAudioPath}/${character}/${timeSlot}.mp3`;
    
    console.log('ğŸ“ Loading recorded audio:', audioPath);
    
    try {
      const response = await fetch(audioPath);
      
      if (!response.ok) {
        throw new Error(`Failed to load recorded audio: ${response.status} ${response.statusText}`);
      }
      
      const audioBlob = await response.blob();
      
      console.log('âœ… Recorded audio loaded:', {
        path: audioPath,
        size: audioBlob.size,
        type: audioBlob.type
      });
      
      return audioBlob;
      
    } catch (error) {
      console.error('âŒ Failed to load recorded audio:', error);
      throw error;
    }
  }

  // çŸ­ã„ç„¡éŸ³ç”Ÿæˆï¼ˆWAVå½¢å¼ï¼‰
  private async generateSilence(durationSeconds: number): Promise<Blob> {
    const sampleRate = 44100;
    const numSamples = Math.floor(sampleRate * durationSeconds);
    const arrayBuffer = new ArrayBuffer(44 + numSamples * 2);
    const view = new DataView(arrayBuffer);

    // WAVãƒ˜ãƒƒãƒ€ãƒ¼
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };

    writeString(0, 'RIFF');
    view.setUint32(4, 36 + numSamples * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, 1, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, numSamples * 2, true);

    // ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ï¼ˆã™ã¹ã¦0ï¼‰
    for (let i = 0; i < numSamples; i++) {
      view.setInt16(44 + i * 2, 0, true);
    }

    return new Blob([arrayBuffer], { type: 'audio/wav' });
  }

  // éŸ³å£°åˆæˆï¼ˆé€£çµï¼‰- Web Audio APIã‚’ä½¿ç”¨
  private async combineAudioBlobs(blobs: Blob[]): Promise<Blob> {
    if (blobs.length === 0) {
      throw new Error('No audio blobs to combine');
    }
    
    if (blobs.length === 1) {
      return blobs[0];
    }

    try {
      const AudioContextClass = window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext;
      const audioContext = new AudioContextClass();
      const audioBuffers: AudioBuffer[] = [];

      // å„Blobã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
      for (const blob of blobs) {
        const arrayBuffer = await blob.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        audioBuffers.push(audioBuffer);
      }

      // åˆè¨ˆæ™‚é–“ã‚’è¨ˆç®—
      const totalDuration = audioBuffers.reduce((sum, buffer) => sum + buffer.duration, 0);
      const sampleRate = audioBuffers[0].sampleRate;
      const totalSamples = Math.floor(totalDuration * sampleRate);

      // åˆæˆç”¨ã®ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
      const combinedBuffer = audioContext.createBuffer(1, totalSamples, sampleRate);
      const combinedData = combinedBuffer.getChannelData(0);

      // éŸ³å£°ã‚’é€£çµ
      let offset = 0;
      for (const buffer of audioBuffers) {
        const channelData = buffer.getChannelData(0);
        combinedData.set(channelData, offset);
        offset += channelData.length;
      }

      // AudioBufferã‚’Blobã«å¤‰æ›
      const wavBlob = await this.audioBufferToBlob(combinedBuffer);
      
      console.log('ğŸ”— Audio combination completed:', {
        inputBlobs: blobs.length,
        totalDuration: totalDuration.toFixed(2) + 's',
        outputSize: wavBlob.size
      });
      
      return wavBlob;

    } catch (error) {
      console.error('âŒ Audio combination failed:', error);
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæœ€åˆã®Blobã®ã¿è¿”ã™
      console.log('âš ï¸ Using fallback: returning first audio blob only');
      return blobs[0];
    }
  }

  // AudioBufferã‚’WAV Blobã«å¤‰æ›
  private async audioBufferToBlob(audioBuffer: AudioBuffer): Promise<Blob> {
    const numChannels = 1;
    const sampleRate = audioBuffer.sampleRate;
    const format = 1; // PCM
    const bitDepth = 16;
    
    const bytesPerSample = bitDepth / 8;
    const blockAlign = numChannels * bytesPerSample;
    const byteRate = sampleRate * blockAlign;
    const dataSize = audioBuffer.length * blockAlign;
    const bufferSize = 44 + dataSize;
    
    const arrayBuffer = new ArrayBuffer(bufferSize);
    const view = new DataView(arrayBuffer);
    
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    // WAVãƒ˜ãƒƒãƒ€ãƒ¼
    writeString(0, 'RIFF');
    view.setUint32(4, bufferSize - 8, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, format, true);
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, byteRate, true);
    view.setUint16(32, blockAlign, true);
    view.setUint16(34, bitDepth, true);
    writeString(36, 'data');
    view.setUint32(40, dataSize, true);
    
    // éŸ³å£°ãƒ‡ãƒ¼ã‚¿
    const channelData = audioBuffer.getChannelData(0);
    let offset = 44;
    for (let i = 0; i < channelData.length; i++) {
      const sample = Math.max(-1, Math.min(1, channelData[i]));
      view.setInt16(offset, sample * 0x7FFF, true);
      offset += 2;
    }
    
    return new Blob([arrayBuffer], { type: 'audio/wav' });
  }

  // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šElevenLabsã§å…¨æ–‡ç”Ÿæˆ
  private async generateFallbackAudio(config: HybridGreetingConfig, timeSlot: TimeSlot): Promise<Blob> {
    console.log('ğŸ”„ Using ElevenLabs fallback for full greeting...');
    
    const greeting = getTimeSlotGreeting(timeSlot);
    const fullText = config.userName ? `${config.userName}ã€${greeting}` : greeting;
    
    try {
      const fallbackAudio = await generateVoice(fullText, config.character);
      console.log('âœ… Fallback audio generated successfully');
      return fallbackAudio;
    } catch (error) {
      console.error('âŒ Fallback audio generation also failed:', error);
      throw error;
    }
  }

  // éŒ²éŸ³éŸ³å£°ã®ã¿å†ç”Ÿï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
  async generateRecordedOnly(character: string, timeSlot?: TimeSlot): Promise<Blob> {
    const slot = timeSlot || getCurrentTimeSlot();
    console.log('ğŸµ Generating recorded-only greeting:', { character, timeSlot: slot });
    
    try {
      return await this.loadRecordedGreeting(character, slot);
    } catch (error) {
      console.error('âŒ Recorded-only generation failed:', error);
      throw error;
    }
  }
}

// ä¾¿åˆ©é–¢æ•°ï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰éŸ³å£°å†ç”Ÿ
export async function playHybridGreeting(userName?: string, timeSlot?: TimeSlot): Promise<void> {
  const hybridEngine = new HybridAudioEngine();
  
  try {
    const audioBlob = await hybridEngine.generateHybridGreeting({
      character: 'akari',
      userName,
      timeSlot
    });
    
    // å†ç”Ÿ
    const audioUrl = URL.createObjectURL(audioBlob);
    const audio = new Audio(audioUrl);
    
    return new Promise((resolve, reject) => {
      audio.onended = () => {
        URL.revokeObjectURL(audioUrl);
        console.log('ğŸ”‡ Hybrid greeting playback completed');
        resolve();
      };
      
      audio.onerror = (error) => {
        URL.revokeObjectURL(audioUrl);
        console.error('âŒ Hybrid greeting playback failed:', error);
        reject(error);
      };
      
      audio.play().catch(reject);
    });
    
  } catch (error) {
    console.error('âŒ Hybrid greeting failed:', error);
    throw error;
  }
}

// ãƒ‡ãƒãƒƒã‚°ç”¨é–¢æ•°
export const debugHybridSystem = () => {
  console.log('ğŸ” Hybrid Audio System Debug:');
  console.log('=' .repeat(50));
  console.log('Available Characters: akari');
  console.log('Base Audio Path: /audio/recorded');
  console.log('Supported Time Slots: morning, afternoon, evening, night');
  console.log('Audio Context Support:', !!(window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext));
  console.log('Fetch API Support:', !!window.fetch);
  console.log('Blob Support:', !!window.Blob);
  console.log('URL Support:', !!window.URL);
};