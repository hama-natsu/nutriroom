// éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ (Web Speech API)
export interface SpeechRecognitionOutput {
  transcript: string
  confidence: number
  isFinal: boolean
}

export interface SpeechRecognitionCallbacks {
  onResult?: (result: SpeechRecognitionOutput) => void
  onStart?: () => void
  onEnd?: () => void
  onError?: (error: string) => void
  onNoMatch?: () => void
}

export class SpeechRecognitionService {
  private recognition: SpeechRecognition | null = null
  private isListening = false
  private callbacks: SpeechRecognitionCallbacks = {}

  constructor() {
    // ãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒã§ã®ã¿åˆæœŸåŒ–
    if (typeof window !== 'undefined') {
      this.initializeRecognition()
    }
  }

  private initializeRecognition(): void {
    // ãƒ–ãƒ©ã‚¦ã‚¶ã‚µãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
    if (typeof window === 'undefined') {
      console.warn('ğŸ™ï¸ Speech Recognition API is not available in server environment')
      return
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    
    if (!SpeechRecognition) {
      console.warn('ğŸ™ï¸ Speech Recognition API is not supported in this browser')
      return
    }

    this.recognition = new SpeechRecognition()
    this.setupRecognitionSettings()
    this.setupEventListeners()
    
    console.log('ğŸ™ï¸ Speech Recognition Service initialized')
  }

  private setupRecognitionSettings(): void {
    if (!this.recognition) return

    // æ—¥æœ¬èªè¨­å®š
    this.recognition.lang = 'ja-JP'
    
    // é€£ç¶šèªè­˜ã‚’æœ‰åŠ¹ã«ã™ã‚‹
    this.recognition.continuous = true
    
    // ä¸­é–“çµæœã‚‚å–å¾—ã™ã‚‹
    this.recognition.interimResults = true
    
    // è‡ªå‹•çµ‚äº†ã¾ã§é•·ã‚ã«è¨­å®š
    this.recognition.maxAlternatives = 1
  }

  private setupEventListeners(): void {
    if (!this.recognition) return

    // èªè­˜é–‹å§‹
    this.recognition.onstart = () => {
      console.log('ğŸ™ï¸ Speech recognition started')
      this.isListening = true
      this.callbacks.onStart?.()
    }

    // èªè­˜çµ‚äº†
    this.recognition.onend = () => {
      console.log('ğŸ™ï¸ Speech recognition ended')
      this.isListening = false
      this.callbacks.onEnd?.()
    }

    // èªè­˜çµæœ
    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        const alternative = result[0]
        const transcript = alternative.transcript

        if (result.isFinal) {
          console.log('ğŸ™ï¸ Final transcript:', transcript)
          
          this.callbacks.onResult?.({
            transcript: transcript.trim(),
            confidence: alternative.confidence,
            isFinal: true
          })
        } else {
          console.log('ğŸ™ï¸ Interim transcript:', transcript)
          
          this.callbacks.onResult?.({
            transcript: transcript.trim(),
            confidence: alternative.confidence,
            isFinal: false
          })
        }
      }
    }

    // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    this.recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      console.error('ğŸ™ï¸ Speech recognition error:', event.error)
      this.isListening = false
      
      let errorMessage = 'éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'
      
      switch (event.error) {
        case 'no-speech':
          errorMessage = 'éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ'
          break
        case 'audio-capture':
          errorMessage = 'ãƒã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸ'
          break
        case 'not-allowed':
          errorMessage = 'ãƒã‚¤ã‚¯ã®ä½¿ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“'
          break
        case 'network':
          errorMessage = 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'
          break
        case 'service-not-allowed':
          errorMessage = 'éŸ³å£°èªè­˜ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“'
          break
        case 'bad-grammar':
          errorMessage = 'éŸ³å£°èªè­˜ã®è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™'
          break
        case 'language-not-supported':
          errorMessage = 'ã“ã®è¨€èªã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“'
          break
      }
      
      this.callbacks.onError?.(errorMessage)
    }

    // ãƒãƒƒãƒã—ãªã„å ´åˆ
    this.recognition.onnomatch = () => {
      console.log('ğŸ™ï¸ No speech match found')
      this.callbacks.onNoMatch?.()
    }
  }

  // éŸ³å£°èªè­˜é–‹å§‹
  public startListening(callbacks: SpeechRecognitionCallbacks = {}): boolean {
    if (!this.recognition) {
      callbacks.onError?.('éŸ³å£°èªè­˜ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“')
      return false
    }

    if (this.isListening) {
      console.log('ğŸ™ï¸ Already listening')
      return false
    }

    this.callbacks = callbacks

    try {
      this.recognition.start()
      return true
    } catch (error) {
      console.error('ğŸ™ï¸ Failed to start speech recognition:', error)
      this.callbacks.onError?.('éŸ³å£°èªè­˜ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ')
      return false
    }
  }

  // éŸ³å£°èªè­˜åœæ­¢
  public stopListening(): void {
    if (!this.recognition || !this.isListening) {
      return
    }

    try {
      this.recognition.stop()
    } catch (error) {
      console.error('ğŸ™ï¸ Failed to stop speech recognition:', error)
    }
  }

  // éŸ³å£°èªè­˜å¼·åˆ¶çµ‚äº†
  public abortListening(): void {
    if (!this.recognition) {
      return
    }

    try {
      this.recognition.abort()
      this.isListening = false
    } catch (error) {
      console.error('ğŸ™ï¸ Failed to abort speech recognition:', error)
    }
  }

  // ãƒ–ãƒ©ã‚¦ã‚¶ã‚µãƒãƒ¼ãƒˆç¢ºèª
  public isSupported(): boolean {
    if (typeof window === 'undefined') {
      return false
    }
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    return !!SpeechRecognition
  }

  // ç¾åœ¨ã®çŠ¶æ…‹ç¢ºèª
  public getIsListening(): boolean {
    return this.isListening
  }

  // ãƒã‚¤ã‚¯æ¨©é™ç¢ºèª
  public async checkMicrophonePermission(): Promise<{
    granted: boolean
    error?: string
  }> {
    try {
      if (typeof window === 'undefined' || typeof navigator === 'undefined') {
        return {
          granted: false,
          error: 'ã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒã§ã¯ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“'
        }
      }

      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        return {
          granted: false,
          error: 'ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“'
        }
      }

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: true,
        video: false 
      })
      
      // ã™ãã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
      stream.getTracks().forEach(track => track.stop())
      
      console.log('ğŸ™ï¸ Microphone permission granted')
      return { granted: true }
      
    } catch (error: unknown) {
      console.error('ğŸ™ï¸ Microphone permission error:', error)
      
      let errorMessage = 'ãƒã‚¤ã‚¯ã®æ¨©é™ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸ'
      
      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          errorMessage = 'ãƒã‚¤ã‚¯ã®ä½¿ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“'
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ'
        } else if (error.name === 'NotReadableError') {
          errorMessage = 'ãƒã‚¤ã‚¯ãŒä½¿ç”¨ä¸­ã¾ãŸã¯åˆ©ç”¨ã§ãã¾ã›ã‚“'
        }
      }
      
      return {
        granted: false,
        error: errorMessage
      }
    }
  }
}

// ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const speechRecognitionService = new SpeechRecognitionService()

// TypeScriptå‹å®šç¾©ã®æ‹¡å¼µ
declare global {
  interface Window {
    SpeechRecognition: typeof SpeechRecognition
    webkitSpeechRecognition: typeof SpeechRecognition
  }
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  grammars: SpeechGrammarList
  interimResults: boolean
  lang: string
  maxAlternatives: number
  serviceURI: string
  start(): void
  stop(): void
  abort(): void
  onaudioend: ((this: SpeechRecognition, ev: Event) => void) | null
  onaudiostart: ((this: SpeechRecognition, ev: Event) => void) | null
  onend: ((this: SpeechRecognition, ev: Event) => void) | null
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => void) | null
  onnomatch: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null
  onsoundend: ((this: SpeechRecognition, ev: Event) => void) | null
  onsoundstart: ((this: SpeechRecognition, ev: Event) => void) | null
  onspeechend: ((this: SpeechRecognition, ev: Event) => void) | null
  onspeechstart: ((this: SpeechRecognition, ev: Event) => void) | null
  onstart: ((this: SpeechRecognition, ev: Event) => void) | null
}

interface SpeechRecognitionErrorEvent extends Event {
  error: 'no-speech' | 'aborted' | 'audio-capture' | 'network' | 'not-allowed' | 'service-not-allowed' | 'bad-grammar' | 'language-not-supported'
  message: string
}

interface SpeechRecognitionEvent extends Event {
  resultIndex: number
  results: SpeechRecognitionResultList
}

interface SpeechRecognitionResultList {
  readonly length: number
  item(index: number): SpeechRecognitionResult
  [index: number]: SpeechRecognitionResult
}

interface SpeechRecognitionResult {
  readonly length: number
  item(index: number): SpeechRecognitionAlternative
  [index: number]: SpeechRecognitionAlternative
  isFinal: boolean
}

interface SpeechRecognitionAlternative {
  transcript: string
  confidence: number
}

interface SpeechGrammarList {
  readonly length: number
  addFromString(string: string, weight?: number): void
  addFromURI(src: string, weight?: number): void
  item(index: number): SpeechGrammar
  [index: number]: SpeechGrammar
}

interface SpeechGrammar {
  src: string
  weight: number
}

declare const SpeechRecognition: {
  prototype: SpeechRecognition
  new(): SpeechRecognition
}