'use client'

import { characterVoiceConfigs, VoiceConfig, VoicePriority, shouldGenerateVoice, getSummarizedTextForVoice } from './voice-config'

// éŸ³å£°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 
class VoiceCache {
  private cache = new Map<string, string>()
  private maxSize = 50 // æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ•°

  getCacheKey(text: string, characterId: string): string {
    return `${characterId}:${text.substring(0, 100)}`
  }

  get(key: string): string | undefined {
    return this.cache.get(key)
  }

  set(key: string, audioUrl: string): void {
    if (this.cache.size >= this.maxSize) {
      // å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
      const firstKey = this.cache.keys().next().value
      if (firstKey) {
        const oldUrl = this.cache.get(firstKey)
        if (oldUrl) {
          URL.revokeObjectURL(oldUrl)
        }
        this.cache.delete(firstKey)
      }
    }
    this.cache.set(key, audioUrl)
  }

  clear(): void {
    // å…¨ã¦ã®URLã‚’è§£æ”¾
    this.cache.forEach(url => URL.revokeObjectURL(url))
    this.cache.clear()
  }
}

export class VoiceService {
  private cache = new VoiceCache()
  private isInitialized = false

  constructor() {
    // ãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒã§ã®ã¿åˆæœŸåŒ–
    if (typeof window !== 'undefined') {
      this.isInitialized = true
    }
  }

  // Google Cloud TTS APIã‚’å‘¼ã³å‡ºã—ï¼ˆã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰çµŒç”±ï¼‰
  async generateVoice(
    text: string, 
    characterId: string, 
    priority: VoicePriority = VoicePriority.GENERAL_CHAT
  ): Promise<string | null> {
    if (!this.isInitialized) {
      console.warn('VoiceService not initialized (server-side)')
      return null
    }

    // éŸ³å£°ç”Ÿæˆã®å¿…è¦æ€§ã‚’åˆ¤å®š
    if (!shouldGenerateVoice(text, priority)) {
      console.log('â­ï¸ Voice generation skipped by policy')
      return null
    }

    // é•·æ–‡ã®å ´åˆã¯è¦ç´„å‡¦ç†ã‚’å®Ÿè¡Œ
    const processedText = getSummarizedTextForVoice(text, characterId)

    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆå‡¦ç†æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆï¼‰
    const cacheKey = this.cache.getCacheKey(processedText, characterId)
    const cachedAudio = this.cache.get(cacheKey)
    if (cachedAudio) {
      console.log('ğŸµ Using cached voice:', {
        originalText: text.substring(0, 30) + (text.length > 30 ? '...' : ''),
        processedText: processedText.substring(0, 30) + (processedText.length > 30 ? '...' : ''),
        cacheKey: cacheKey.substring(0, 30) + '...'
      })
      return cachedAudio
    }

    try {
      console.log('ğŸ¤ Generating voice for:', {
        characterId,
        originalText: text.substring(0, 30) + (text.length > 30 ? '...' : ''),
        originalLength: text.length,
        processedText: processedText.substring(0, 30) + (processedText.length > 30 ? '...' : ''),
        processedLength: processedText.length,
        wasProcessed: text !== processedText,
        priority,
        timestamp: new Date().toISOString()
      })
      
      const voiceConfig = characterVoiceConfigs[characterId]
      if (!voiceConfig) {
        console.error('âŒ Voice config not found for character:', characterId)
        return null
      }

      console.log('ğŸµ Using voice config:', {
        characterId,
        languageCode: voiceConfig.languageCode,
        voiceName: voiceConfig.name,
        personality: voiceConfig.personality
      })

      // ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã®TTS APIã‚’å‘¼ã³å‡ºã—
      console.log('ğŸ“¡ Sending TTS API request...')
      const response = await fetch('/api/text-to-speech', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          text: processedText.substring(0, 200), // å‡¦ç†æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã€200æ–‡å­—åˆ¶é™
          characterId,
          voiceConfig
        })
      })

      console.log('ğŸ“¡ TTS API response status:', response.status)

      if (!response.ok) {
        const errorText = await response.text()
        console.error('âŒ TTS API failed:', {
          status: response.status,
          statusText: response.statusText,
          error: errorText
        })
        throw new Error(`TTS API failed: ${response.status} - ${errorText}`)
      }

      // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’Blobã¨ã—ã¦å–å¾—
      console.log('ğŸ“¦ Processing audio response...')
      const audioBlob = await response.blob()
      console.log('ğŸ“¦ Audio blob size:', audioBlob.size, 'bytes')
      
      const audioUrl = URL.createObjectURL(audioBlob)
      console.log('ğŸ”— Audio URL created:', audioUrl.substring(0, 50) + '...')

      // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
      this.cache.set(cacheKey, audioUrl)
      console.log('ğŸ’¾ Audio cached with key:', cacheKey.substring(0, 30) + '...')

      console.log('âœ… Voice generated successfully:', {
        characterId,
        text: text.substring(0, 30),
        audioSize: audioBlob.size,
        cacheKey: cacheKey.substring(0, 30) + '...'
      })
      return audioUrl

    } catch (error) {
      console.error('âŒ Voice generation failed:', {
        characterId,
        text: text.substring(0, 30),
        error: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : undefined
      })
      return null
    }
  }

  // éŸ³å£°ã‚’å†ç”Ÿï¼ˆæ”¹å–„ç‰ˆ - é€”åˆ‡ã‚Œå•é¡Œå¯¾ç­–ï¼‰
  async playVoice(audioUrl: string): Promise<void> {
    if (!this.isInitialized) {
      console.warn('âš ï¸ VoiceService not initialized - cannot play audio')
      return
    }

    try {
      console.log('ğŸ”Š Starting enhanced audio playback:', audioUrl.substring(0, 50) + '...')
      const audio = new Audio(audioUrl)
      
      // éŸ³å£°ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å¼·åŒ–è¨­å®š
      audio.preload = 'auto'
      audio.volume = 0.85 // éŸ³é‡è¨­å®š
      audio.crossOrigin = 'anonymous' // CORSå¯¾å¿œ
      
      // éŸ³å£°å†ç”Ÿå“è³ªå‘ä¸Šã®ãŸã‚ã®è¨­å®š
      if ('webkitAudioContext' in window || 'AudioContext' in window) {
        console.log('ğŸ§ Enhanced audio context available')
      }
      
      console.log('ğŸµ Audio element created with enhanced settings...')
      
      return new Promise((resolve, reject) => {
        let isResolved = false
        const timeout = setTimeout(() => {
          if (!isResolved) {
            console.warn('â° Audio playback timeout (30s)')
            isResolved = true
            reject(new Error('Audio playback timeout'))
          }
        }, 30000) // 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

        // å®Œäº†æ™‚ã®å‡¦ç†
        const handleComplete = () => {
          if (!isResolved) {
            console.log('âœ… Audio playback completed successfully')
            clearTimeout(timeout)
            isResolved = true
            resolve()
          }
        }

        // ã‚¨ãƒ©ãƒ¼å‡¦ç†
        const handleError = () => {
          if (!isResolved) {
            console.error('âŒ Audio playback error:', {
              currentTime: audio.currentTime,
              duration: audio.duration,
              readyState: audio.readyState,
              networkState: audio.networkState
            })
            clearTimeout(timeout)
            isResolved = true
            reject(new Error('Audio playback failed'))
          }
        }

        // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼è¨­å®š
        audio.onended = handleComplete
        audio.onerror = handleError
        audio.onabort = handleError
        
        // é€²è¡ŒçŠ¶æ³ã®è©³ç´°ãƒ­ã‚°
        audio.onloadstart = () => console.log('ğŸ“¥ Audio loading started')
        audio.onloadeddata = () => console.log('ğŸ“Š Audio data loaded')
        audio.oncanplay = () => console.log('â–¶ï¸ Audio ready to play')
        audio.oncanplaythrough = () => console.log('ğŸ¯ Audio can play through')
        audio.onprogress = () => {
          if (audio.buffered.length > 0) {
            const bufferedEnd = audio.buffered.end(audio.buffered.length - 1)
            const duration = audio.duration || 0
            const bufferedPercent = duration > 0 ? (bufferedEnd / duration * 100).toFixed(1) : '0'
            console.log(`ğŸ“Š Audio buffered: ${bufferedPercent}%`)
          }
        }
        
        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ãƒ­ãƒ¼ãƒ‰å¾…æ©Ÿ
        const attemptPlay = () => {
          if (audio.readyState >= 2) { // HAVE_CURRENT_DATAä»¥ä¸Š
            console.log('ğŸµ Starting audio playback (readyState:', audio.readyState, ')')
            audio.play().then(() => {
              console.log('ğŸµ Audio playback started successfully:', {
                duration: audio.duration,
                currentTime: audio.currentTime,
                volume: audio.volume,
                readyState: audio.readyState
              })
            }).catch(error => {
              console.warn('âš ï¸ Audio autoplay failed:', error)
              if (!isResolved) {
                clearTimeout(timeout)
                isResolved = true
                reject(error)
              }
            })
          } else {
            console.log('â³ Waiting for audio data to load (readyState:', audio.readyState, ')')
            setTimeout(attemptPlay, 100) // 100mså¾Œã«å†è©¦è¡Œ
          }
        }

        // ãƒ­ãƒ¼ãƒ‰å®Œäº†æ™‚ã«å†ç”Ÿé–‹å§‹
        audio.oncanplay = () => {
          console.log('â–¶ï¸ Audio ready to play, attempting playback...')
          attemptPlay()
        }
      })
    } catch (error) {
      console.error('âŒ Audio playback setup error:', {
        error: error instanceof Error ? error.message : String(error),
        audioUrl: audioUrl.substring(0, 50) + '...'
      })
      throw error
    }
  }

  // éŸ³å£°ç”Ÿæˆ + å†ç”Ÿ
  async generateAndPlay(
    text: string, 
    characterId: string, 
    priority: VoicePriority = VoicePriority.GENERAL_CHAT
  ): Promise<boolean> {
    const startTime = Date.now()
    console.log('ğŸ¬ Starting voice generation and playback workflow:', {
      characterId,
      text: text.substring(0, 30),
      priority,
      timestamp: new Date().toISOString()
    })

    try {
      const audioUrl = await this.generateVoice(text, characterId, priority)
      if (!audioUrl) {
        console.log('â­ï¸ Voice generation skipped - returning false')
        return false
      }

      await this.playVoice(audioUrl)
      
      const duration = Date.now() - startTime
      console.log('ğŸ‰ Voice workflow completed successfully:', {
        characterId,
        text: text.substring(0, 30),
        duration: `${duration}ms`,
        success: true
      })
      return true
    } catch (error) {
      const duration = Date.now() - startTime
      console.error('âŒ Voice generation and play failed:', {
        characterId,
        text: text.substring(0, 30),
        duration: `${duration}ms`,
        error: error instanceof Error ? error.message : String(error),
        success: false
      })
      return false
    }
  }

  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
  clearCache(): void {
    console.log('ğŸ—‘ï¸ Clearing voice cache...')
    const cacheSize = this.cache['cache'].size
    this.cache.clear()
    console.log(`âœ… Voice cache cleared (${cacheSize} items removed)`)
  }

  // éŸ³å£°å¯¾å¿œãƒã‚§ãƒƒã‚¯
  isVoiceSupported(): boolean {
    const isSupported = this.isInitialized && typeof Audio !== 'undefined'
    console.log('ğŸ” Voice support check:', {
      isInitialized: this.isInitialized,
      hasAudio: typeof Audio !== 'undefined',
      isSupported,
      browser: typeof navigator !== 'undefined' ? navigator.userAgent.substring(0, 50) : 'unknown'
    })
    return isSupported
  }

  // ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼éŸ³å£°è¨­å®šå–å¾—
  getVoiceConfig(characterId: string): VoiceConfig | null {
    const config = characterVoiceConfigs[characterId] || null
    console.log('ğŸ­ Getting voice config for character:', {
      characterId,
      found: !!config,
      config: config ? {
        languageCode: config.languageCode,
        voiceName: config.name,
        personality: config.personality
      } : null
    })
    return config
  }
}

// ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const voiceService = new VoiceService()