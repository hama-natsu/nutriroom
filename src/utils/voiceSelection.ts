// ğŸ¯ NutriRoom çµ±ä¸€éŸ³å£°é¸æŠã‚¨ãƒ³ã‚¸ãƒ³ - ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨é™¤å»ç‰ˆ

import { 
  CharacterId,
  handleUnifiedVoiceResponse,
  selectUnifiedVoice,
  getUnifiedTimeSlot
} from '@/lib/unified-voice-system'

import { 
  TimeSlot, 
  EmotionState, 
  InteractionContext, 
  VoicePattern, 
  CharacterVoiceProfile,
  VoiceSelectionRequest,
  VoiceSelectionResult,
  VoiceFileInfo,
  SmartVoiceConfig
} from '@/types/voiceTypes'

// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
const DEFAULT_CONFIG: SmartVoiceConfig = {
  baseAudioPath: '/audio/recorded',
  supportedFormats: ['.wav'], // WAVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚µãƒãƒ¼ãƒˆ
  fallbackEnabled: true,
  cacheEnabled: true,
  debugMode: process.env.NODE_ENV === 'development'
}

// ã‚ã‹ã‚Šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®éŸ³å£°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
const AKARI_VOICE_PROFILE: CharacterVoiceProfile = {
  characterId: 'akari',
  preferredPatterns: ['cheerful', 'gentle', 'normal'],
  timeSlotPreferences: {
    morning: ['cheerful', 'energetic', 'early'],
    afternoon: ['normal', 'gentle', 'cheerful'],
    evening: ['gentle', 'calm', 'normal'],
    night: ['gentle', 'calm', 'late']
  },
  emotionMappings: {
    energetic: ['cheerful', 'energetic', 'early'],
    normal: ['normal', 'gentle', 'cheerful'],
    tired: ['gentle', 'calm', 'late'],
    excited: ['cheerful', 'energetic', 'early'],
    calm: ['gentle', 'calm', 'normal'],
    worried: ['gentle', 'calm', 'normal']
  },
  contextMappings: {
    greeting: ['cheerful', 'early', 'gentle'],
    response: ['normal', 'gentle', 'cheerful'],
    encouragement: ['cheerful', 'energetic', 'early'],
    explanation: ['normal', 'gentle', 'calm'],
    goodbye: ['gentle', 'normal', 'cheerful']
  }
}

// ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼éŸ³å£°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
const CHARACTER_PROFILES: Record<string, CharacterVoiceProfile> = {
  akari: AKARI_VOICE_PROFILE
}

/**
 * ç¾åœ¨ã®æ™‚é–“å¸¯ã‚’åˆ¤å®šï¼ˆçµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ï¼‰
 */
export function getCurrentTimeSlot(): TimeSlot {
  const unifiedSlot = getUnifiedTimeSlot()
  
  // çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ãƒ¬ã‚¬ã‚·ãƒ¼å½¢å¼ã«å¤‰æ›
  switch (unifiedSlot) {
    case 'morning_early':
    case 'morning':
    case 'morning_late':
      return 'morning'
    case 'lunch':
    case 'afternoon':
    case 'snack':
      return 'afternoon'
    case 'evening':
    case 'dinner':
      return 'evening'
    case 'night':
    case 'late':
    case 'very_late':
    default:
      return 'night'
  }
}

/**
 * ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ„Ÿæƒ…çŠ¶æ…‹ã‚’æ¨å®š
 */
export function analyzeEmotionFromMessage(message: string): EmotionState {
  const energeticKeywords = ['å…ƒæ°—', 'é ‘å¼µ', 'ã‚„ã‚‹æ°—', 'æ¥½ã—ã„', 'å¬‰ã—ã„', 'æœ€é«˜']
  const tiredKeywords = ['ç–²ã‚Œ', 'çœ ã„', 'ã ã‚‹ã„', 'è¾›ã„', 'å¤§å¤‰']
  const excitedKeywords = ['ã™ã”ã„', 'æœ€é«˜', 'ã‚„ã£ãŸ', 'æ„Ÿå‹•', 'èˆˆå¥®']
  const worriedKeywords = ['å¿ƒé…', 'ä¸å®‰', 'å›°ã£ãŸ', 'ã©ã†ã—ã‚ˆã†', 'æ‚©ã¿']
  const calmKeywords = ['è½ã¡ç€', 'é™ã‹', 'ç©ã‚„ã‹', 'ãƒªãƒ©ãƒƒã‚¯ã‚¹']

  const lowerMessage = message.toLowerCase()
  
  if (energeticKeywords.some(keyword => lowerMessage.includes(keyword))) {
    return 'energetic'
  }
  if (excitedKeywords.some(keyword => lowerMessage.includes(keyword))) {
    return 'excited'
  }
  if (tiredKeywords.some(keyword => lowerMessage.includes(keyword))) {
    return 'tired'
  }
  if (worriedKeywords.some(keyword => lowerMessage.includes(keyword))) {
    return 'worried'
  }
  if (calmKeywords.some(keyword => lowerMessage.includes(keyword))) {
    return 'calm'
  }
  
  return 'normal'
}

/**
 * ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ¤å®š
 */
export function determineInteractionContext(
  userMessage: string, 
  conversationHistory: string[] = []
): InteractionContext {
  const lowerMessage = userMessage.toLowerCase()
  
  // åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¾ãŸã¯æŒ¨æ‹¶ã®å ´åˆ
  if (conversationHistory.length === 0 || 
      ['ã“ã‚“ã«ã¡ã¯', 'ãŠã¯ã‚ˆã†', 'ã“ã‚“ã°ã‚“ã¯', 'ã¯ã˜ã‚ã¾ã—ã¦'].some(greeting => 
        lowerMessage.includes(greeting))) {
    return 'greeting'
  }
  
  // åˆ¥ã‚Œã®æŒ¨æ‹¶
  if (['ã•ã‚ˆã†ãªã‚‰', 'ã¾ãŸ', 'ã‚ã‚ŠãŒã¨ã†', 'ãƒã‚¤ãƒã‚¤'].some(farewell => 
      lowerMessage.includes(farewell))) {
    return 'goodbye'
  }
  
  // åŠ±ã¾ã—ãŒå¿…è¦ãªå ´åˆ
  if (['é ‘å¼µã‚‹', 'æŒ‘æˆ¦', 'ç›®æ¨™', 'ãƒãƒ£ãƒ¬ãƒ³ã‚¸', 'åŠªåŠ›'].some(encouragement => 
      lowerMessage.includes(encouragement))) {
    return 'encouragement'
  }
  
  // èª¬æ˜ã‚’æ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆ
  if (['ãªãœ', 'ã©ã†ã—ã¦', 'ç†ç”±', 'èª¬æ˜', 'æ•™ãˆã¦', 'ãªã«'].some(question => 
      lowerMessage.includes(question))) {
    return 'explanation'
  }
  
  return 'response'
}

/**
 * éŸ³å£°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠï¼ˆå„ªå…ˆåº¦ãƒ™ãƒ¼ã‚¹ï¼‰
 */
export function selectVoicePattern(
  characterId: string,
  timeSlot: TimeSlot,
  emotionState: EmotionState,
  interactionContext: InteractionContext
): { pattern: VoicePattern; confidence: number; reason: string } {
  const profile = CHARACTER_PROFILES[characterId]
  if (!profile) {
    return { 
      pattern: 'normal', 
      confidence: 0.3, 
      reason: 'Unknown character, using default pattern' 
    }
  }

  // å„è¦ç´ ã‹ã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³å€™è£œã‚’åé›†
  const timePatterns = profile.timeSlotPreferences[timeSlot] || []
  const emotionPatterns = profile.emotionMappings[emotionState] || []
  const contextPatterns = profile.contextMappings[interactionContext] || []
  const preferredPatterns = profile.preferredPatterns || []

  // ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚³ã‚¢è¨ˆç®—
  const patternScores: Record<VoicePattern, number> = {} as Record<VoicePattern, number>
  
  // æ™‚é–“å¸¯ã‚¹ã‚³ã‚¢ (é‡ã¿: 25%)
  timePatterns.forEach((pattern, index) => {
    patternScores[pattern] = (patternScores[pattern] || 0) + (0.25 * (timePatterns.length - index) / timePatterns.length)
  })
  
  // æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ (é‡ã¿: 35%)
  emotionPatterns.forEach((pattern, index) => {
    patternScores[pattern] = (patternScores[pattern] || 0) + (0.35 * (emotionPatterns.length - index) / emotionPatterns.length)
  })
  
  // ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚³ã‚¢ (é‡ã¿: 30%)
  contextPatterns.forEach((pattern, index) => {
    patternScores[pattern] = (patternScores[pattern] || 0) + (0.30 * (contextPatterns.length - index) / contextPatterns.length)
  })
  
  // ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åŸºæœ¬è¨­å®šã‚¹ã‚³ã‚¢ (é‡ã¿: 10%)
  preferredPatterns.forEach((pattern, index) => {
    patternScores[pattern] = (patternScores[pattern] || 0) + (0.10 * (preferredPatterns.length - index) / preferredPatterns.length)
  })

  // æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
  const bestPattern = Object.entries(patternScores).reduce((best, [pattern, score]) => 
    score > best.score ? { pattern: pattern as VoicePattern, score } : best, 
    { pattern: 'normal' as VoicePattern, score: 0 }
  )

  const confidence = Math.min(bestPattern.score, 1.0)
  const reason = `Selected based on time:${timeSlot}, emotion:${emotionState}, context:${interactionContext}`

  return {
    pattern: bestPattern.pattern,
    confidence,
    reason
  }
}

/**
 * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
 */
export function generateVoiceFileName(
  timeSlot: TimeSlot,
  pattern: VoicePattern,
  format: string = '.wav'
): string {
  return `${timeSlot}_${pattern}${format}`
}

/**
 * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ããƒ»ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰
 */
export async function checkVoiceFileExists(
  characterId: string, 
  fileName: string, 
  config: SmartVoiceConfig = DEFAULT_CONFIG
): Promise<VoiceFileInfo> {
  const filePath = `${config.baseAudioPath}/${characterId}/${fileName}`
  const CHECK_TIMEOUT = 3000 // 3ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
  
  try {
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), CHECK_TIMEOUT)
    
    const response = await fetch(filePath, { 
      method: 'HEAD',
      signal: controller.signal
    })
    
    clearTimeout(timeoutId)
    
    const fileInfo: VoiceFileInfo = {
      fileName,
      exists: response.ok,
      size: response.ok ? parseInt(response.headers.get('content-length') || '0') : undefined
    }
    
    if (config.debugMode && response.ok) {
      console.log('âœ… Voice file exists:', filePath, `(${fileInfo.size} bytes)`)
    }
    
    return fileInfo
    
  } catch (error) {
    if (error instanceof Error && error.name === 'AbortError') {
      console.warn(`â° Voice file check timeout for ${filePath}`)
    } else {
      console.warn(`âŒ Voice file check failed for ${filePath}:`, error instanceof Error ? error.message : 'Unknown error')
    }
    return {
      fileName,
      exists: false
    }
  }
}

/**
 * ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å€™è£œã‚’ç”Ÿæˆ
 */
export function generateFallbackOptions(
  timeSlot: TimeSlot,
  originalPattern: VoicePattern,
  characterId: string
): string[] {
  const profile = CHARACTER_PROFILES[characterId]
  const fallbackPatterns = profile?.preferredPatterns || ['normal', 'gentle', 'cheerful']
  
  const options: string[] = []
  
  // åŒã˜æ™‚é–“å¸¯ã§ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
  fallbackPatterns.forEach(pattern => {
    if (pattern !== originalPattern) {
      options.push(generateVoiceFileName(timeSlot, pattern))
    }
  })
  
  // REMOVED: No default.wav fallback - system should handle gracefully
  // options.push('default.wav')  // DELETED: Eliminates default.wav dependency
  
  return options
}

/**
 * ãƒ¡ã‚¤ãƒ³éŸ³å£°é¸æŠã‚¨ãƒ³ã‚¸ãƒ³
 */
export async function selectSmartVoice(
  request: VoiceSelectionRequest,
  config: SmartVoiceConfig = DEFAULT_CONFIG
): Promise<VoiceSelectionResult> {
  const timeSlot = request.timeSlot || getCurrentTimeSlot()
  const emotionState = request.emotionState || 
    (request.userMessage ? analyzeEmotionFromMessage(request.userMessage) : 'normal')
  const interactionContext = request.interactionContext || 
    (request.userMessage ? determineInteractionContext(request.userMessage, request.conversationHistory) : 'response')

  const { pattern, confidence, reason } = selectVoicePattern(
    request.characterId,
    timeSlot,
    emotionState,
    interactionContext
  )

  const fileName = generateVoiceFileName(timeSlot, pattern)
  const filePath = `${config.baseAudioPath}/${request.characterId}/${fileName}`
  const fallbackOptions = generateFallbackOptions(timeSlot, pattern, request.characterId)

  if (config.debugMode) {
    console.log('ğŸ¤– Smart Voice Selection:', {
      characterId: request.characterId,
      timeSlot,
      emotionState,
      interactionContext,
      selectedPattern: pattern,
      confidence,
      fileName,
      reason
    })
  }

  return {
    fileName,
    filePath,
    pattern,
    confidence,
    fallbackOptions,
    selectionReason: reason
  }
}

// ã€çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã€‘ãƒ¡ã‚¤ãƒ³éŸ³å£°é¸æŠé–¢æ•°ï¼ˆå…¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¯¾å¿œï¼‰
export async function selectAndPlayUnifiedVoice(
  characterId: string,
  aiResponse?: string,
  isGreeting: boolean = false
): Promise<boolean> {
  console.log('ğŸ¯ çµ±ä¸€éŸ³å£°é¸æŠã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨');
  
  // æ–‡å­—åˆ—ã‚’CharacterIdã«å¤‰æ›
  const validCharacters = ['akari', 'minato', 'yuki', 'riku', 'mao', 'satsuki', 'sora'];
  if (!validCharacters.includes(characterId)) {
    console.log(`âŒ æœªå¯¾å¿œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: ${characterId}`);
    return false;
  }
  
  return await handleUnifiedVoiceResponse(
    characterId as CharacterId,
    aiResponse,
    isGreeting
  );
}

// ã€çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã€‘éŸ³å£°é¸æŠã®ã¿ï¼ˆå†ç”Ÿãªã—ï¼‰
export function selectUnifiedVoiceOnly(
  characterId: string,
  aiResponse?: string,
  isGreeting: boolean = false
): { voiceFile: string | null; shouldPlay: boolean; reason: string } {
  console.log('ğŸ¯ çµ±ä¸€éŸ³å£°é¸æŠï¼ˆå†ç”Ÿãªã—ï¼‰');
  
  const validCharacters = ['akari', 'minato', 'yuki', 'riku', 'mao', 'satsuki', 'sora'];
  if (!validCharacters.includes(characterId)) {
    console.log(`âŒ æœªå¯¾å¿œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: ${characterId}`);
    return { voiceFile: null, shouldPlay: false, reason: 'Unsupported character' };
  }
  
  return selectUnifiedVoice(
    characterId as CharacterId,
    aiResponse,
    isGreeting
  );
}

/**
 * ãƒ‡ãƒãƒƒã‚°ç”¨é–¢æ•°
 */
export const debugSmartVoiceSystem = () => {
  console.log('ğŸ¯ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ  Debug:')
  console.log('=' .repeat(50))
  console.log('å¯¾å¿œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼:', ['akari', 'minato', 'yuki', 'riku', 'mao', 'satsuki', 'sora'])
  console.log('ç¾åœ¨ã®æ™‚é–“å¸¯:', getUnifiedTimeSlot())
  console.log('æ™‚é–“å¸¯ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°:', 11)
  console.log('æ„Ÿæƒ…ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°:', 16)
  console.log('å­£ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°:', 4)
  console.log('éŸ³å£°å½¢å¼: WAV')
  console.log('ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ : ğŸ—‘ï¸ å®Œå…¨é™¤å»æ¸ˆã¿')
  console.log('çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‘½å: âœ… character_pattern.wav')
  console.log('=' .repeat(50))
}